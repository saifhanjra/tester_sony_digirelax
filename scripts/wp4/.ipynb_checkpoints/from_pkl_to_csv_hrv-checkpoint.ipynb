{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62977e33-68b6-440c-94fc-7cee4bd83de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "\n",
    "# misc\n",
    "import warnings\n",
    "\n",
    "import glob\n",
    "\n",
    "##\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2159b3b5-8ac6-46a4-95a6-3521e4b303a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#style settings\n",
    "sns.set(style='whitegrid', rc={'axes.facecolor': 'white'})\n",
    "\n",
    "#sns.set_style({'font.family':'Arial', 'font.serif':'Times New Roman'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3c5723-1266-4b43-a396-aff739ac861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timedomain(rr):\n",
    "    results = {}\n",
    "\n",
    "    hr = 60000/rr\n",
    "    \n",
    "    results['Mean RR (ms)'] = np.mean(rr)\n",
    "    results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "    results['Mean HR (Kubios\\' style) (beats/min)'] = 60000/np.mean(rr)\n",
    "    results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "    results['STD HR (beats/min)'] = np.std(hr)\n",
    "    results['Min HR (beats/min)'] = np.min(hr)\n",
    "    results['Max HR (beats/min)'] = np.max(hr)\n",
    "    results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "    results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 50)*1\n",
    "    results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 50)*1) / len(rr)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d53c92-6e89-4f4a-a3db-7144c9af6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_nan_values_cols(p_df, col_name):\n",
    "    \n",
    "    slic_ind=p_df[col_name].isnull()\n",
    "    list_ne=slic_ind.tolist()\n",
    "    false_indices = [i for i in range(len(list_ne)) if not list_ne[i]]\n",
    "    \n",
    "    list_col_interest=p_df[col_name].to_list()\n",
    "    \n",
    "    non_values_list = []\n",
    "    \n",
    "    for false_ind in false_indices:\n",
    "        non_val = list_col_interest[false_ind]\n",
    "        non_values_list.append(non_val)\n",
    "    \n",
    "    return non_values_list\n",
    "\n",
    "\n",
    "def get_file_names_from_ind_list(files_list, inds_list):\n",
    "    \n",
    "    selected_files_list=[files_list[sel_index] for sel_index in inds_list]\n",
    "    \n",
    "    return selected_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08aefab4-ea46-478e-9223-c41d75111eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_pickled_condition_files(path_pickled_files_list, cond_file_names_list):\n",
    "    selected_file_cond_list = []\n",
    "    \n",
    "    for selected_file_path in path_pickled_files_list:\n",
    "        dir_path, file_name=os.path.split(selected_file_path)\n",
    "        sub_id = file_name[0:12]\n",
    "    \n",
    "        for cond_file in cond_file_names_list:\n",
    "        \n",
    "            if sub_id==cond_file:\n",
    "            \n",
    "                selected_file_cond_list.append(selected_file_path)\n",
    "                #print(selected_file_path)\n",
    "                \n",
    "    return selected_file_cond_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6cecf7-e146-40f1-8a3e-a0c9848c83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(all_rr_one_list, all_rr_sublist):\n",
    "    \n",
    "    mean_norm_list =[]\n",
    "    std_norm_list = []\n",
    "    \n",
    "    mean_norm_bpm_list = []\n",
    "    std_norm_bpm_list = []\n",
    "    \n",
    "    all_rr_one_list = np.array(all_rr_one_list)\n",
    "    max_val = np.max(all_rr_one_list)\n",
    "    min_val =np.min(all_rr_one_list)\n",
    "    \n",
    "    range_list = max_val-min_val\n",
    "    \n",
    "    ####-------beats per minutes--------\n",
    "    bpm_one_list = 60000/all_rr_one_list\n",
    "    \n",
    "    max_bpm = np.max(bpm_one_list)\n",
    "    \n",
    "    min_bpm = np.min(bpm_one_list)\n",
    "    \n",
    "    range_bpm =  max_bpm - min_bpm\n",
    "    \n",
    "    \n",
    "    for sel_list in all_rr_sublist:\n",
    "        \n",
    "        sel_list_np = np.array(sel_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "        sel_lis_np_sub = sel_list_np - min_val\n",
    "        \n",
    "        sel_lis_norm= sel_lis_np_sub/range_list\n",
    "        \n",
    "        mean_norm = np.mean(sel_lis_norm)\n",
    "        mean_norm_list.append(mean_norm)\n",
    "        \n",
    "        std_norm  = np.std(sel_lis_norm)   \n",
    "        std_norm_list.append(std_norm)\n",
    "        \n",
    "        ##------------for normalized BPM----------\n",
    "        \n",
    "        sel_list_bpm = 60000/sel_list_np\n",
    "        \n",
    "        \n",
    "        \n",
    "        sel_bpm_min_sub = sel_list_bpm - min_bpm\n",
    "        \n",
    "        sel_bpm_list_norm =  sel_bpm_min_sub/ range_bpm\n",
    "        \n",
    "        mean_norm_bpm = np.mean(sel_bpm_list_norm)\n",
    "        \n",
    "        std_norm_bpm = np.std(sel_bpm_list_norm)\n",
    "        \n",
    "        mean_norm_bpm_list.append(mean_norm_bpm)\n",
    "        \n",
    "        std_norm_bpm_list.append(std_norm_bpm)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(mean_norm)\n",
    "        #print(std_norm)\n",
    "                \n",
    "        \n",
    "    return mean_norm_list, std_norm_list, mean_norm_bpm_list, std_norm_bpm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4bb7e5-e579-4413-9a99-1b0f6d0a07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_bpm(mean_bpm_list):\n",
    "    \n",
    "    base_line = mean_bpm_list[0]\n",
    "    tsst  = np.mean(mean_bpm_list[1:4])\n",
    "    relax = np.mean(mean_bpm_list[4:])\n",
    "    \n",
    "    #tsst  = max(mean_bpm_list[1:4])\n",
    "    #relax = min(mean_bpm_list[4:])\n",
    "\n",
    "    new_array = [base_line,tsst, relax]\n",
    "    \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7588e6-38de-4edd-bde7-835d6931a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_cond(input_array):\n",
    "    \n",
    "    mean_diff = np.diff(input_array)\n",
    "    \n",
    "    mean_diff = np.insert(mean_diff, [0], 0)\n",
    "    \n",
    "    mean_diff_cumsum = np.cumsum(mean_diff, dtype=float)\n",
    "    \n",
    "    return (mean_diff_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfc7c43-125d-46de-ac1b-80b3531e9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_rate_change_percent(cond_phy_array):\n",
    "    \n",
    "    prev_val = cond_phy_array[1]\n",
    "    curr_val = cond_phy_array[2]\n",
    "    change_val=((curr_val-prev_val)/abs(prev_val))\n",
    "    change_percent = change_val*100\n",
    "    #print(change_percent)\n",
    "    \n",
    "    return change_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5ad726-26f9-4f7e-932b-acc8dd379cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_rr_to_time_anal(selected_path):\n",
    "                 \n",
    "    with open(selected_path, 'rb') as f:\n",
    "        ibi_data = pickle.load(f)\n",
    "                    \n",
    "                    \n",
    "    subject_id = ibi_data[\"subject_id\"]\n",
    "    event_interst = ibi_data[\"event_interst\"]\n",
    "    all_rr_one_list = ibi_data[\"all_rr_one_list\"]\n",
    "    all_rr_sublists = ibi_data[\"all_rr_sublists\"]\n",
    "            \n",
    "    max_rr = np.max(all_rr_one_list)\n",
    "    #print(max_rr)\n",
    "    min_rr = np.min(all_rr_one_list)\n",
    "    #print(min_rr)\n",
    "    range_rr = max_rr - min_rr    \n",
    "            \n",
    "    mean_rr_cumm_list = []\n",
    "    std_rr_cumm_list  = []\n",
    "    mean_hr_list = []\n",
    "    std_hr_list = []\n",
    "            \n",
    "    for index, selected_event in enumerate(event_interst):\n",
    "        sel_rr = all_rr_sublists[index]\n",
    "                \n",
    "        #### heart rate from RR ineterval\n",
    "        hr_from_rr = 60000/sel_rr\n",
    "        mean_hr = np.mean(hr_from_rr)\n",
    "        std_hr = np.std(hr_from_rr)\n",
    "        mean_hr_list.append(mean_hr)\n",
    "        std_hr_list.append(std_hr)\n",
    "                \n",
    "        ##### mean and std rr\n",
    "        mean_rr = np.mean(sel_rr)     \n",
    "        std_rr = np.std(sel_rr)\n",
    "        mean_rr_cumm_list.append(mean_rr)\n",
    "        std_rr_cumm_list.append(std_rr)\n",
    "                \n",
    "                \n",
    "    mean_norm_hrv_list, std_norm_hrv_list,  mean_norm_bpm_list, std_norm_bpm_list = min_max_norm(all_rr_one_list, all_rr_sublists)\n",
    "            \n",
    "    export_dict= {\"subject_id\":subject_id , 'event_interst': event_interst, \"mean_bpm\": mean_hr_list, \"std_bpm\":std_hr_list , \n",
    "                              \"mean_ibi\":mean_rr_cumm_list , \"std_ibi\": std_rr_cumm_list , \"norm_mean_ibi\":mean_norm_hrv_list,  \"norm_std_ibi\": std_norm_hrv_list,\n",
    "                             \"norm_mean_bpm\":mean_norm_bpm_list, \"norm_std_bpm\":  std_norm_bpm_list, \"rmssd\": ibi_data[\"rmssd\"]}\n",
    "            \n",
    "            \n",
    "    return export_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a7a9ba9-918b-4f1b-bab3-569ead9f2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rr_stage_1(rr, throshold_high=0.5, threshold_low=0.5):\n",
    "    \n",
    "    #outlier_high = np.mean(rr) + throshold_high * np.std(rr)\n",
    "    outlier_high =1200\n",
    "    #print(outlier_high)\n",
    "    \n",
    "    rr_clean_high = [rr_val for rr_val in rr if rr_val <  outlier_high]\n",
    "    \n",
    "    rr_clean_high = np.array(rr_clean_high)\n",
    "    \n",
    "    #outlier_low = np.mean(rr_clean_high) - threshold_low*np.std(rr_clean_high)\n",
    "    outlier_low = 400\n",
    "    #print(outlier_low)\n",
    "    \n",
    "    rr_clean_high_low = [rr_val for rr_val in rr_clean_high if rr_val >  outlier_low]\n",
    "    \n",
    "    rr_clean_high_low= np.array(rr_clean_high_low)\n",
    "    \n",
    "    return rr_clean_high_low\n",
    "\n",
    "\n",
    "\n",
    "def remove_outliers_rri(r_peaks_diff_msec, sampling_freq = 256, outlier_std = 2):\n",
    "    \n",
    "    # RR-intervals are the differences between successive peaks\n",
    "    #r_peaks_sec = r_peaks*1/sampling_freq\n",
    "    #r_peaks_msec = r_peaks_sec*1000\n",
    "\n",
    "    #r_peaks_diff=np.diff(r_peaks_msec)\n",
    "    \n",
    "    rr_corrected = r_peaks_diff_msec.copy()\n",
    "\n",
    "    rr_corrected[np.abs(zscore(r_peaks_diff_msec)) > outlier_std] = np.median(r_peaks_diff_msec)\n",
    "    \n",
    "    return rr_corrected\n",
    "\n",
    "\n",
    "\n",
    "def from_rr_to_rr_interpolated(rr_msec, fs = 4):\n",
    "    #create interpolation function based on the r-r samples\n",
    "    \n",
    "    # sample in seconds(x-axis)\n",
    "    x = np.cumsum(rr_msec)/1200 \n",
    "    f = interp1d(x, rr_msec, kind='cubic')\n",
    "    \n",
    "    steps = 1/fs\n",
    "    \n",
    "    # now we can sample from interpolation function\n",
    "    xx = np.arange(1, np.max(x), steps)\n",
    "    rr_interpolated_msec = f(xx)\n",
    "    \n",
    "    return rr_interpolated_msec\n",
    "\n",
    "def frequency_domain_rr(rri, fs=4):\n",
    "    # rri: rr interpolated\n",
    "    # Estimate the spectral density using Welch's method\n",
    "    fxx, pxx = signal.welch(x=rri, fs=fs)\n",
    "    \n",
    "    '''\n",
    "    Segement found frequencies in the bands \n",
    "     - Very Low Frequency (VLF): 0-0.04Hz \n",
    "     - Low Frequency (LF): 0.04-0.15Hz \n",
    "     - High Frequency (HF): 0.15-0.4Hz\n",
    "    '''\n",
    "    cond_vlf = (fxx >= 0) & (fxx < 0.04)\n",
    "    cond_lf = (fxx >= 0.04) & (fxx < 0.15)\n",
    "    cond_hf = (fxx >= 0.15) & (fxx < 0.4)\n",
    "    \n",
    "    # calculate power in each band by integrating the spectral density \n",
    "    vlf = trapz(pxx[cond_vlf], fxx[cond_vlf])\n",
    "    lf = trapz(pxx[cond_lf], fxx[cond_lf])\n",
    "    hf = trapz(pxx[cond_hf], fxx[cond_hf])\n",
    "    \n",
    "    # sum these up to get total power\n",
    "    total_power = vlf + lf + hf\n",
    "\n",
    "    # find which frequency has the most power in each band\n",
    "    peak_vlf = fxx[cond_vlf][np.argmax(pxx[cond_vlf])]\n",
    "    peak_lf = fxx[cond_lf][np.argmax(pxx[cond_lf])]\n",
    "    peak_hf = fxx[cond_hf][np.argmax(pxx[cond_hf])]\n",
    "\n",
    "    # fraction of lf and hf\n",
    "    lf_nu = 100 * lf / (lf + hf)\n",
    "    hf_nu = 100 * hf / (lf + hf)\n",
    "    \n",
    "    results = {}\n",
    "    results['Power VLF (ms2)'] = vlf\n",
    "    results['Power LF (ms2)'] = lf\n",
    "    results['Power HF (ms2)'] = hf   \n",
    "    results['Power Total (ms2)'] = total_power\n",
    "\n",
    "    results['LF/HF'] = (lf/hf)\n",
    "    results['Peak VLF (Hz)'] = peak_vlf\n",
    "    results['Peak LF (Hz)'] = peak_lf\n",
    "    results['Peak HF (Hz)'] = peak_hf\n",
    "\n",
    "    results['Fraction LF (nu)'] = lf_nu\n",
    "    results['Fraction HF (nu)'] = hf_nu\n",
    "    return results, fxx, pxx\n",
    "\n",
    "def from_rr_to_freq_anal(selected_path):\n",
    "                 \n",
    "    with open(selected_path, 'rb') as f:\n",
    "        ibi_data = pickle.load(f)\n",
    "                    \n",
    "                    \n",
    "    subject_id = ibi_data[\"subject_id\"]\n",
    "    event_interst = ibi_data[\"event_interst\"]\n",
    "    all_rr_one_list = ibi_data[\"all_rr_one_list\"]\n",
    "    all_rr_sublists = ibi_data[\"all_rr_sublists\"]\n",
    "            \n",
    "    max_rr = np.max(all_rr_one_list)\n",
    "    #print(max_rr)\n",
    "    min_rr = np.min(all_rr_one_list)\n",
    "    #print(min_rr)\n",
    "    range_rr = max_rr - min_rr    \n",
    "            \n",
    "    vlf_cumm_list = []\n",
    "    lf_cumm_list  = []\n",
    "    hf_cumm_list = []\n",
    "    total_power_list = []\n",
    "    #std_hr_list = []\n",
    "            \n",
    "    for index, selected_event in enumerate(event_interst):\n",
    "        sel_rr = all_rr_sublists[index]\n",
    "        rr_filtered_stage_1= filter_rr_stage_1(sel_rr)\n",
    "        rr_filtered=remove_outliers_rri(rr_filtered_stage_1)\n",
    "        interpolated_rr = from_rr_to_rr_interpolated(rr_filtered, fs = 4)\n",
    "        \n",
    "        print(np.max(interpolated_rr))\n",
    "        results_freq, fxx, pxx =frequency_domain_rr(interpolated_rr)\n",
    "        \n",
    "        vlf=results_freq['Power VLF (ms2)']\n",
    "        lf= results_freq['Power LF (ms2)']\n",
    "        hf=results_freq['Power HF (ms2)']   \n",
    "        total_power=results_freq['Power Total (ms2)']\n",
    "        \n",
    "                \n",
    "        #### heart rate from RR ineterval\n",
    "        #hr_from_rr = 60000/sel_rr\n",
    "        #mean_hr = np.mean(hr_from_rr)\n",
    "        #std_hr = np.std(hr_from_rr)\n",
    "        #mean_hr_list.append(mean_hr)\n",
    "        #std_hr_list.append(std_hr)\n",
    "                \n",
    "        ##### mean and std rr\n",
    "        #mean_rr = np.mean(sel_rr)     \n",
    "        #std_rr = np.std(sel_rr)\n",
    "        #mean_rr_cumm_list.append(mean_rr)\n",
    "        \n",
    "        vlf_cumm_list.append(vlf)\n",
    "        lf_cumm_list.append(lf)\n",
    "        hf_cumm_list.append(hf)\n",
    "        total_power_list.append(total_power)\n",
    "                \n",
    "                \n",
    "    #mean_norm_hrv_list, std_norm_hrv_list,  mean_norm_bpm_list, std_norm_bpm_list = min_max_norm(all_rr_one_list, all_rr_sublists)\n",
    "            \n",
    "    export_dict= {\"subject_id\":subject_id , 'event_interst': event_interst, \"vlf_power\": vlf_cumm_list, \"lf_power\":lf_cumm_list , \n",
    "                              \"hf_power\":hf_cumm_list , \"total_power\": total_power_list}\n",
    "            \n",
    "            \n",
    "    return export_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1104fe8-2188-4c6b-8e3a-a8f2fe00b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hrv_data_dir = \"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp4/results_final_report\"\n",
    "hrv_data_dir = \"C:/Users/muhammad.saif/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp4/results_final_report/ecg_analysis/ecg_timadomain_pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3eb94f06-eacb-4cb5-b58f-9cb819abc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dest_path = \"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp4/results_final_report/from_pkl_to_csv\"\n",
    "dest_path = \"D:/Datasets/data_sony_digiRelax/anal_freq_domain\"\n",
    "#designated_folder = \"hrv_analysis\"\n",
    "#comp_dest_path = os.path.join(dest_path, designated_folder)\n",
    "\n",
    "isexist = os.path.exists(dest_path)\n",
    "\n",
    "#if not isexist:\n",
    "#    os.makedirs(comp_dest_path)\n",
    "#    print(\"The new directory is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "766c88de-4328-48db-ab6c-0e4f7a3d6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrv_files_list = glob.glob(hrv_data_dir+ \"/*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90526390-9b19-44cd-8c7f-613b9d09fa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33fb001d-0d69-4e5b-82da-2d79b4d5ce84",
   "metadata": {},
   "source": [
    "## for time domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32196a7a-2ce6-4c4e-8573-cf542727f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel_file in hrv_files_list:\n",
    "    fol_path, file_name_ii=os.path.split(sel_file)\n",
    "    file_name_ii = file_name_ii[:-4]\n",
    "    \n",
    "    hr_data_dict = from_rr_to_time_anal(sel_file)\n",
    "    \n",
    "    csv_time_domain_feat_filename = file_name_ii + \".csv\"\n",
    "    dest_path_csv = os.path.join(dest_path,csv_time_domain_feat_filename)\n",
    "    print(dest_path_csv)\n",
    "    df_export = pd.DataFrame.from_dict(hr_data_dict)\n",
    "    df_export.to_csv(dest_path_csv)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca30306-4406-400e-a9ea-769b8b000af5",
   "metadata": {},
   "source": [
    "## For frequency domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2bc66fe-10bb-49d8-886a-7dc711b32602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP004_081123_DigiRelax_Experiment_2023-11-08_10h28.36.317\n",
      "1108.1610130757404\n",
      "1103.424224181717\n",
      "1107.2262746365693\n",
      "1020.9911152308171\n",
      "1131.560884780443\n",
      "1102.5057393387806\n",
      "1100.78115336708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammad.saif\\Anaconda3\\lib\\site-packages\\scipy\\signal\\_spectral_py.py:1999: UserWarning: nperseg = 256 is greater than input length  = 251, using nperseg = 251\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP005_081123_DigiRelax_Experiment_2023-11-08_14h17.35.226\n",
      "1065.5548245024274\n",
      "735.9203737346922\n",
      "618.4478550156284\n",
      "761.4768280051321\n",
      "1105.0872286837598\n",
      "1171.8174030195419\n",
      "1100.234664387957\n",
      "VP006_091123_DigiRelax_Experiment_2023-11-09_10h17.40.415\n",
      "685.7483108652754\n",
      "648.5134600159568\n",
      "611.6109031297428\n",
      "658.9021267479962\n",
      "777.1310804459838\n",
      "753.9152896855126\n",
      "748.300197529858\n",
      "VP007_091123_DigiRelax_Experiment_2023-11-09_14h19.56.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muhammad.saif\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\muhammad.saif\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6764\\1185760772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mfile_name_ii\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_name_ii\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_ii\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mhr_data_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_rr_to_freq_anal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcsv_time_domain_feat_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_name_ii\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6764\\819066477.py\u001b[0m in \u001b[0;36mfrom_rr_to_freq_anal\u001b[1;34m(selected_path)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mrr_filtered_stage_1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfilter_rr_stage_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msel_rr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mrr_filtered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremove_outliers_rri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr_filtered_stage_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0minterpolated_rr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_rr_to_rr_interpolated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr_filtered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterpolated_rr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6764\\819066477.py\u001b[0m in \u001b[0;36mfrom_rr_to_rr_interpolated\u001b[1;34m(rr_msec, fs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# sample in seconds(x-axis)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr_msec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrr_msec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cubic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\interpolate\\_interpolate.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# Interpolation goes internally along the first axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reshape_yi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m  \u001b[1;31m# clean up namespace to prevent misuse; use attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\interpolate\\_polyint.py\u001b[0m in \u001b[0;36m_reshape_yi\u001b[1;34m(self, yi, check)\u001b[0m\n\u001b[0;32m    108\u001b[0m                                            self._y_extra_shape[:-self._y_axis])\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be of shape %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mok_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_yi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "for sel_file in hrv_files_list:\n",
    "    fol_path, file_name_ii=os.path.split(sel_file)\n",
    "    file_name_ii = file_name_ii[:-4]\n",
    "    print(file_name_ii)\n",
    "    hr_data_dict = from_rr_to_freq_anal(sel_file)\n",
    "    \n",
    "    csv_time_domain_feat_filename = file_name_ii + \".csv\"\n",
    "    dest_path_csv = os.path.join(dest_path,csv_time_domain_feat_filename)\n",
    "    #print(dest_path_csv)\n",
    "    df_export = pd.DataFrame.from_dict(hr_data_dict)\n",
    "    df_export.to_csv(dest_path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857aa32-b07d-49ac-9030-6f0b7e4f4852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4300b-9fff-4d08-a96d-9854602aff68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
