{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f494f18c-6cea-4017-9f1a-a458d8345869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "\n",
    "# misc\n",
    "import warnings\n",
    "\n",
    "import glob\n",
    "\n",
    "##\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d28d5-000e-4d17-82c7-b9f2c6591662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becea94c-695e-4fba-93c7-72b9d757644c",
   "metadata": {},
   "source": [
    "## Psychopy Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e765042-766d-4762-9699-380986cc5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manipulate_psychopy(psychopy_path):\n",
    "    \n",
    "    psychopy_df = pd.read_csv(psychopy_path)\n",
    "    col_list = [col for col in psychopy_df.columns if col.endswith('_ts')]\n",
    "    col_list.insert(0, \"Reference_time\")\n",
    "    psychopy_df_selected = psychopy_df[col_list]\n",
    "    \n",
    "    return psychopy_df_selected\n",
    "\n",
    "\n",
    "def get_nonNan_list_psychopy(psychopy_df, col_name):\n",
    "    \n",
    "    \n",
    "    selected_vals=[val for val in psychopy_df[col_name].to_list() if not(math.isnan(val))]\n",
    "    \n",
    "    return selected_vals\n",
    "\n",
    "\n",
    "\n",
    "#######---------------------------------------------------\n",
    "###### ------------------Shimmer--------------------------\n",
    "###----------------------------------------------------------\n",
    "\n",
    "\n",
    "def read_shimmer_sensor(sensor_file_path):\n",
    "    \n",
    "    shimmer_df = pd.read_csv(sensor_file_path, sep='\\t', low_memory=False)\n",
    "    shimmer_df = shimmer_df.reset_index()\n",
    "    shimmer_df.columns = shimmer_df.iloc[0]\n",
    "    shimmer_df.drop([0, 1], axis=0, inplace=True)\n",
    "    shimmer_df=shimmer_df.reset_index(drop=True)\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "def standardize_timestamps_shimmer(shimmer_df, timestamps_col_name):\n",
    "    \n",
    "    timesstamps_list = shimmer_df[timestamps_col_name].to_list()\n",
    "    new_timestamps_list = [float(val)/1000 for val in  timesstamps_list]\n",
    "    \n",
    "    shimmer_df[timestamps_col_name] = new_timestamps_list\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "\n",
    "\n",
    "def get_offset_timestamp(timestamp, offset_mins):\n",
    "    \n",
    "    time_zone = 'Europe/Berlin'\n",
    "    tz = pytz.timezone(time_zone)\n",
    "    local_time = dt.datetime.fromtimestamp(timestamp, tz)\n",
    "    time_change = dt.timedelta(minutes=offset_mins)\n",
    "    new_time = local_time + time_change\n",
    "    new_timestamp =  dt.datetime.timestamp(new_time)\n",
    "    return new_timestamp\n",
    "\n",
    "def get_list_timestamp_interest(starting_timestamp, list_offset_mins):\n",
    "    \n",
    "    starting_timestamp_list=[]\n",
    "    \n",
    "    for offset_min in list_offset_mins:\n",
    "        starting_timestamp_list.append(starting_timestamp)\n",
    "        timestamp_offset = get_offset_timestamp(starting_timestamp, offset_min)\n",
    "        starting_timestamp = timestamp_offset  \n",
    "     \n",
    "    \n",
    "    #starting_timestamp_list = sorted(starting_timestamp_list, key = lambda x:float(x))\n",
    "    return starting_timestamp_list\n",
    "        \n",
    "        \n",
    "\n",
    "def slice_df_wrt_timestamps(df, start_timestamp, end_timestamp, timestamps_col):\n",
    "    \n",
    "    sliced_df=df[(df[timestamps_col]>= start_timestamp) & (df[timestamps_col] <= end_timestamp)]\n",
    "    \n",
    "    return sliced_df\n",
    "\n",
    "\n",
    "def from_str_to_float(str_list):\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    return float_array\n",
    "\n",
    "def col_from_str_float (df, col_name):\n",
    "    \n",
    "    str_list = df[col_name].values\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    df[col_name] = float_array\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf5f94-f734-4d84-9998-b457fa874110",
   "metadata": {},
   "source": [
    "## HRV: Time domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f65d0ff5-1954-40d0-a7d4-658f3bc70190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):\n",
    "    '''\n",
    "    Peak detection algorithm using cross corrrelation and threshold \n",
    "    '''\n",
    "    if qrs_filter is None:\n",
    "        # create default qrs filter, which is just a part of the sine function\n",
    "        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)\n",
    "        qrs_filter = np.sin(t)\n",
    "    \n",
    "    # normalize data\n",
    "    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()\n",
    "\n",
    "    # calculate cross correlation\n",
    "    similarity = np.correlate(ecg_signal, qrs_filter, mode=\"same\")\n",
    "    similarity = similarity / np.max(similarity)\n",
    "\n",
    "    # return peaks (values in ms) using threshold\n",
    "    return ecg_signal[similarity > threshold].index, similarity\n",
    "\n",
    "\n",
    "\n",
    "def group_peaks(p, threshold=5):\n",
    "    '''\n",
    "    The peak detection algorithm finds multiple peaks for each QRS complex. \n",
    "    Here we group collections of peaks that are very near (within threshold) and we take the median index \n",
    "    '''\n",
    "    # initialize output\n",
    "    output = np.empty(0)\n",
    "\n",
    "    # label groups of sample that belong to the same peak\n",
    "    peak_groups, num_groups = label(np.diff(p) < threshold)\n",
    "\n",
    "    # iterate through groups and take the mean as peak index\n",
    "    for i in np.unique(peak_groups)[1:]:\n",
    "        peak_group = p[np.where(peak_groups == i)]\n",
    "        output = np.append(output, np.median(peak_group))\n",
    "    return output\n",
    "\n",
    "def group_peaks_from_ind_to_msec(grouped_peaks_ind, sampling_freq):\n",
    "    \n",
    "    \n",
    "    #grouped_peak_ascending = sorted(grouped_peaks_ind, key = lambda x:float(x))\n",
    "    \n",
    "    #grouped_peak_ascending_np=np.array(grouped_peak_ascending)\n",
    "    grouped_peak_sec = grouped_peaks_ind*(1/sampling_freq)\n",
    "    \n",
    "    grouped_peak_msec = grouped_peak_sec*1000\n",
    "    \n",
    "    return grouped_peak_msec\n",
    "    \n",
    "\n",
    "\n",
    "def timedomain(rr):\n",
    "    results = {}\n",
    "\n",
    "    hr = 60000/rr\n",
    "    \n",
    "    results['Mean RR (ms)'] = np.mean(rr)\n",
    "    results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "    #results['Mean HR (Kubios\\' style) (beats/min)'] = 60000/np.mean(rr)\n",
    "    #results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "    #results['STD HR (beats/min)'] = np.std(hr)\n",
    "    #results['Min HR (beats/min)'] = np.min(hr)\n",
    "    #results['Max HR (beats/min)'] = np.max(hr)\n",
    "    results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "    results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 100)*1\n",
    "    results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 100)*1) / len(rr)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def filter_rr(rr, throshold_high=0.5, threshold_low=0.5):\n",
    "    \n",
    "    #outlier_high = np.mean(rr) + throshold_high * np.std(rr)\n",
    "    outlier_high =1500\n",
    "    #print(outlier_high)\n",
    "    \n",
    "    rr_clean_high = [rr_val for rr_val in rr if rr_val <  outlier_high]\n",
    "    \n",
    "    rr_clean_high = np.array(rr_clean_high)\n",
    "    \n",
    "    #outlier_low = np.mean(rr_clean_high) - threshold_low*np.std(rr_clean_high)\n",
    "    outlier_low = 400\n",
    "    #print(outlier_low)\n",
    "    \n",
    "    rr_clean_high_low = [rr_val for rr_val in rr_clean_high if rr_val >  outlier_low]\n",
    "    \n",
    "    rr_clean_high_low= np.array(rr_clean_high_low)\n",
    "    \n",
    "    return rr_clean_high_low\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def min_max_norm(all_rr_one_list, all_rr_sublist):\n",
    "    \n",
    "    mean_norm_list =[]\n",
    "    std_norm_list = []\n",
    "    \n",
    "    all_rr_one_list = np.array(all_rr_one_list)\n",
    "    max_val = np.max(all_rr_one_list)\n",
    "    min_val =np.min(all_rr_one_list)\n",
    "    \n",
    "    for sel_list in all_rr_sublist:\n",
    "        \n",
    "        sel_list_np = np.array(sel_list)\n",
    "        \n",
    "        range_list = max_val-min_val\n",
    "        \n",
    "        sel_lis_np_sub = sel_list_np - min_val\n",
    "        \n",
    "        sel_lis_norm= sel_lis_np_sub/range_list\n",
    "        \n",
    "        mean_norm = np.mean(sel_lis_norm)\n",
    "        mean_norm_list.append(mean_norm)\n",
    "        \n",
    "        std_norm  = np.std(sel_lis_norm)   \n",
    "        std_norm_list.append(std_norm)\n",
    "        #print(mean_norm)\n",
    "        #print(std_norm)\n",
    "                \n",
    "        \n",
    "    return mean_norm_list, std_norm_list\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def get_plot_ranges(start=10, end=20, n=5):\n",
    "    '''\n",
    "    Make an iterator that divides into n or n+1 ranges. \n",
    "    - if end-start is divisible by steps, return n ranges\n",
    "    - if end-start is not divisible by steps, return n+1 ranges, where the last range is smaller and ends at n\n",
    "    \n",
    "    # Example:\n",
    "    >> list(get_plot_ranges())\n",
    "    >> [(0.0, 3.0), (3.0, 6.0), (6.0, 9.0)]\n",
    "\n",
    "    '''\n",
    "    distance = end - start\n",
    "    for i in np.arange(start, end, np.floor(distance/n)):\n",
    "        yield (int(i), int(np.minimum(end, np.floor(distance/n) + i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520976e-dfeb-4c03-a217-d87faceb2b59",
   "metadata": {},
   "source": [
    "## Path and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc024e62-5c15-483e-81c3-c1ea4e3ad618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7da6bf2-a774-474f-84a5-d0e6e4378f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"/home/muhammad/Desktop/Datasets/data_sony_digiRelax/wp3\"\n",
    "#data_dir_path = \"D:/Datasets/data_sony_digiRelax/study\"\n",
    "sub_dirs=next(os.walk(data_dir_path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61cabf64-698d-4f5b-ad30-22110d082406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VP055_141223',\n",
       " 'VP057_151223',\n",
       " 'VP020_221123',\n",
       " 'VP009_101123',\n",
       " 'VP072_120124',\n",
       " 'VP026_271123',\n",
       " 'VP038_051223',\n",
       " 'VP050_131223',\n",
       " 'VP029_281123',\n",
       " 'VP042_071223',\n",
       " 'VP019_201123',\n",
       " 'VP039_061223',\n",
       " 'VP044_071223',\n",
       " 'VP068_100124',\n",
       " 'VP035_041223',\n",
       " 'VP014_151123',\n",
       " 'VP045_081223',\n",
       " 'VP034_011223',\n",
       " 'VP037_051223',\n",
       " 'VP006_091123',\n",
       " 'VP013_151123',\n",
       " 'VP064_050124',\n",
       " 'VP040_061223',\n",
       " 'VP047_111223',\n",
       " 'VP052_131223',\n",
       " 'VP043_071223',\n",
       " 'VP018_201123',\n",
       " 'VP048_121223',\n",
       " 'VP054_141223',\n",
       " 'VP021_221123',\n",
       " 'VP010_131123',\n",
       " 'VP031_291123',\n",
       " 'VP046_081223',\n",
       " 'VP024_241123',\n",
       " 'VP028_281123',\n",
       " 'VP061_191223',\n",
       " 'VP032_301123',\n",
       " 'VP051_131223',\n",
       " 'VP007_091123',\n",
       " 'VP069_110124',\n",
       " 'VP015_161123',\n",
       " 'VP011_131123',\n",
       " 'VP027_271123',\n",
       " 'VP025_271123',\n",
       " 'VP016_161123',\n",
       " 'VP004_081123',\n",
       " 'VP070_110124',\n",
       " 'VP012_141123',\n",
       " 'VP060_191223',\n",
       " 'VP022_231123',\n",
       " 'VP063_040124',\n",
       " 'VP067_100124',\n",
       " 'VP049_121223',\n",
       " 'VP065_050124',\n",
       " 'VP071_120124',\n",
       " 'VP033_301123',\n",
       " 'VP005_081123',\n",
       " 'VP053_141223',\n",
       " 'VP008_101123',\n",
       " 'VP056_151223',\n",
       " 'VP041_061223',\n",
       " 'VP023_231123',\n",
       " 'VP059_181223',\n",
       " 'VP017_171123',\n",
       " 'VP030_291123',\n",
       " 'VP066_080124',\n",
       " 'VP058_181223']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad3201b-e38e-42f6-bf9e-aa09188935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_event_list(psychopy_df, shimmer_df_selected, event_interest_list_new, offset_min_list_new, timestamp_sensor_col_name, data_col_name):\n",
    "\n",
    "    mean_cumm_list = []\n",
    "    std_cumm_list  = []\n",
    "    event_interets_plot = []\n",
    "    \n",
    "    all_rr_one_list = []\n",
    "    all_rr_sublist = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ##---outer loop to hnadle muultiple offsets from the selected events \n",
    "    for ind, event_selected in enumerate(event_interest_list_new):\n",
    "\n",
    "        offset_list_selected_event = offset_min_list_new[ind]\n",
    "\n",
    "        #print(event_selected)\n",
    "\n",
    "        current_event_timestamp = get_nonNan_list_psychopy(psychopy_df, event_selected)[0]\n",
    "\n",
    "        offset_min_list_selected = offset_min_list_new[ind]\n",
    "        \n",
    "        acc_min_print = 0\n",
    "\n",
    "        for offset_min in offset_min_list_selected:\n",
    "            \n",
    "            offset_min_print = offset_min + acc_min_print\n",
    "            \n",
    "            acc_min_print = offset_min_print\n",
    "\n",
    "            event_plot = event_selected +\" \"+ str(offset_min_print) + \" min\"\n",
    "            \n",
    "            print(event_plot)\n",
    "            \n",
    "            event_interets_plot.append(event_plot)\n",
    "\n",
    "            timestamp_offset = get_offset_timestamp(current_event_timestamp, offset_min)\n",
    "\n",
    "            start_end_time_list = [current_event_timestamp, timestamp_offset]\n",
    "\n",
    "            timestamp_start_slice = min(start_end_time_list)\n",
    "\n",
    "            timestamp_end_slice = max(start_end_time_list)\n",
    "\n",
    "            sensor_df_ii=slice_df_wrt_timestamps(shimmer_df_selected, timestamp_start_slice, timestamp_end_slice, timestamp_sensor_col_name)\n",
    "            \n",
    "            #print(sensor_df_ii)\n",
    "            \n",
    "            ecg_df_ii=sensor_df_ii.reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            #cond_slice_main = (ecg_df_ii[timestamp_sensor_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_sensor_col_name] < timestamp_end_slice)\n",
    "            \n",
    "            ecg_slice = ecg_df_ii.heartrate\n",
    "            \n",
    "            peaks, similarity = detect_peaks(ecg_slice, threshold=0.3)\n",
    "            grouped_peaks = group_peaks(peaks)\n",
    "            grouped_peak_msec =group_peaks_from_ind_to_msec(grouped_peaks, 256)\n",
    "            rr = np.diff(grouped_peak_msec)\n",
    "            #print(timedomain(rr))\n",
    "            cleaned_rr = filter_rr(rr)\n",
    "            mean_rr = np.mean(cleaned_rr) \n",
    "            std_rr = np.std(cleaned_rr)\n",
    "            \n",
    "            mean_cumm_list.append(mean_rr)\n",
    "            std_cumm_list.append(std_rr)\n",
    "            \n",
    "            all_rr_one_list.extend(cleaned_rr)\n",
    "            all_rr_sublist.append(cleaned_rr)\n",
    "            \n",
    "            \n",
    "            #event_interets_plot\n",
    "            \n",
    "            #print(np.mean(cleaned_rr))\n",
    "            #print(np.std(cleaned_rr))\n",
    "            \n",
    "\n",
    "\n",
    "            current_event_timestamp = timestamp_offset\n",
    "            \n",
    "            \n",
    "            \n",
    "    return mean_cumm_list, std_cumm_list, event_interets_plot, all_rr_one_list, all_rr_sublist\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bd5cf4-835c-41d5-b73e-4bef45a7d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_hrv_new_event_list(psychopy_df, shimmer_df_selected, event_interest_list_new, offset_min_list_new, timestamp_sensor_col_name, data_col_name):\n",
    "\n",
    "    mean_cumm_list = []\n",
    "    std_cumm_list  = []\n",
    "    event_interets_plot = []\n",
    "    \n",
    "    all_rr_one_list = []\n",
    "    all_rr_sublist = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ##---outer loop to hnadle muultiple offsets from the selected events \n",
    "    for ind, event_selected in enumerate(event_interest_list_new):\n",
    "\n",
    "        offset_list_selected_event = offset_min_list_new[ind]\n",
    "\n",
    "        #print(event_selected)\n",
    "\n",
    "        current_event_timestamp = get_nonNan_list_psychopy(psychopy_df, event_selected)[0]\n",
    "\n",
    "        offset_min_list_selected = offset_min_list_new[ind]\n",
    "        \n",
    "        acc_min_print = 0\n",
    "\n",
    "        for offset_min in offset_min_list_selected:\n",
    "            \n",
    "            offset_min_print = offset_min + acc_min_print\n",
    "            \n",
    "            acc_min_print = offset_min_print\n",
    "\n",
    "            event_plot = event_selected +\" \"+ str(offset_min_print) + \" min\"\n",
    "            \n",
    "            print(event_plot)\n",
    "            \n",
    "            event_interets_plot.append(event_plot)\n",
    "\n",
    "            timestamp_offset = get_offset_timestamp(current_event_timestamp, offset_min)\n",
    "\n",
    "            start_end_time_list = [current_event_timestamp, timestamp_offset]\n",
    "\n",
    "            timestamp_start_slice = min(start_end_time_list)\n",
    "\n",
    "            timestamp_end_slice = max(start_end_time_list)\n",
    "\n",
    "            sensor_df_ii=slice_df_wrt_timestamps(shimmer_df_selected, timestamp_start_slice, timestamp_end_slice, timestamp_sensor_col_name)\n",
    "            \n",
    "            #print(sensor_df_ii)\n",
    "            \n",
    "            ecg_df_ii=sensor_df_ii.reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            #cond_slice_main = (ecg_df_ii[timestamp_sensor_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_sensor_col_name] < timestamp_end_slice)\n",
    "            \n",
    "            ecg_slice = ecg_df_ii.heartrate\n",
    "            \n",
    "            peaks, similarity = detect_peaks(ecg_slice, threshold=0.3)\n",
    "            grouped_peaks = group_peaks(peaks)\n",
    "            grouped_peak_msec =group_peaks_from_ind_to_msec(grouped_peaks, 256)\n",
    "            rr = np.diff(grouped_peak_msec)\n",
    "            #print(timedomain(rr))\n",
    "            cleaned_rr = filter_rr(rr)\n",
    "            mean_rr = np.mean(cleaned_rr) \n",
    "            std_rr = np.std(cleaned_rr)\n",
    "            \n",
    "            mean_cumm_list.append(mean_rr)\n",
    "            std_cumm_list.append(std_rr)\n",
    "            \n",
    "            all_rr_one_list.extend(cleaned_rr)\n",
    "            all_rr_sublist.append(cleaned_rr)\n",
    "            \n",
    "            \n",
    "            #event_interets_plot\n",
    "            \n",
    "            #print(np.mean(cleaned_rr))\n",
    "            #print(np.std(cleaned_rr))\n",
    "            \n",
    "\n",
    "\n",
    "            current_event_timestamp = timestamp_offset\n",
    "            \n",
    "            \n",
    "            \n",
    "    return mean_cumm_list, std_cumm_list, event_interets_plot, all_rr_one_list, all_rr_sublist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788fd7b-ba3a-48bc-a2a5-22fdf4baaea0",
   "metadata": {},
   "source": [
    "## Fetching and slicing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3213a9c8-508b-40ae-a348-b038ae64a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#event_interest_list_new = [\"baseline_instruction_ts\", \"tsst_prep_ts\", \"tsst_pres_ts\", \"relaxation_prep_ts\", \"saliva_probe_4_ts\", \"saliva_probe_4_ts\"]\n",
    "event_interest_list_new = [\"baseline_instruction_ts\", \"tsst_prep_ts\", \"tsst_pres_ts\", \"relaxation_prep_ts\"]\n",
    "offset_min_list_new  = [[3], [5], [5,5], [5, 5, 5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "030fbb2c-6e50-4c08-a8e0-cbd1e3605811",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path =\"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp3/results_22sub\"\n",
    "#dest_path = \"D:/Datasets/analysis_digirelax\"\n",
    "designated_folder = \"hrv_analysis\"\n",
    "comp_dest_path = os.path.join(dest_path, designated_folder)\n",
    "\n",
    "isexist = os.path.exists(comp_dest_path)\n",
    "\n",
    "if not isexist:\n",
    "    os.makedirs(comp_dest_path)\n",
    "    print(\"The new directory is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2013beaa-2353-4899-add6-6bc6c651d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP055_141223_DigiRelax_Experiment_2023-12-14_15h45.35.483\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP057_151223_DigiRelax_Experiment_2023-12-15_15h00.46.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP020_221123_DigiRelax_Experiment_2023-11-22_09h48.04.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP009_101123_DigiRelax_Experiment_2023-11-10_14h16.47.223\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP072_120124_DigiRelax_Experiment_2024-01-12_14h45.23.547\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP26_271123_DigiRelax_Experiment_2023-11-27_13h16.52.357\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP038_051223_DigiRelax_Experiment_2023-12-05_15h52.43.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP050_131223_DigiRelax_Experiment_2023-12-13_09h49.36.277\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP029_281123_DigiRelax_Experiment_2023-11-28_15h49.00.382\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP042_071223_DigiRelax_Experiment_2023-12-07_10h46.20.248\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP019_201123_DigiRelax_Experiment_2023-11-20_14h48.37.367\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP039_061223_DigiRelax_Experiment_2023-12-06_09h56.18.635\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP044_071223_DigiRelax_Experiment_2023-12-07_15h47.55.663\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP068_100124_DigiRelax_Experiment_2024-01-10_14h41.55.244\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP035_041123_DigiRelax_Experiment_2023-12-04_09h54.08.642\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP014_151123_DigiRelax_Experiment_2023-11-15_14h23.06.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP045_081223_DigiRelax_Experiment_2023-12-08_09h50.13.039\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP034_011223_DigiRelax_Experiment_2023-12-01_14h41.10.723\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP037_051223_DigiRelax_Experiment_2023-12-05_10h01.53.815\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP006_091123_DigiRelax_Experiment_2023-11-09_10h17.40.415\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP013_151123_DigiRelax_Experiment_2023-11-15_09h52.50.734\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP064_050124_DigiRelax_Experiment_2024-01-05_09h44.11.070\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP040_061223_DigiRelax_Experiment_2023-12-06_13h18.31.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP047_111223_DigiRelax_Experiment_2023-12-11_14h40.20.997\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP052_131223_DigiRelax_Experiment_2023-12-13_15h40.02.531\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP043_071223_DigiRelax_Experiment_2023-12-07_13h24.11.749\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP018_201123_DigiRelax_Experiment_2023-11-20_09h51.59.612\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP048_121223_DigiRelax_Experiment_2023-12-12_09h46.06.539\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP054_141223_DigiRelax_Experiment_2023-12-14_13h16.33.883\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP021_221123_DigiRelax_Experiment_2023-11-22_14h43.57.344\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP010_131123_DigiRelax_Experiment_2023-11-13_09h54.08.913\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP031_291123_DigiRelax_Experiment_2023-11-29_14h41.15.470\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "Vp046_081223_DigiRelax_Experiment_2023-12-08_14h49.59.665\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP024_241123_DigiRelax_Experiment_2023-11-24_15h57.15.078\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP028_281123_DigiRelax_Experiment_2023-11-28_13h11.36.660\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "VP061_191223_DigiRelax_Experiment_2023-12-19_15h10.55.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/home/muhammad/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_instruction_ts 3 min\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "first array argument cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m selected_ecg_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheartrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m selected_ecg_df[ecg_col_name]\n\u001b[1;32m     36\u001b[0m selected_ecg_df\u001b[38;5;241m=\u001b[39mcol_from_str_float(selected_ecg_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheartrate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m mean_hrv_list,std_hrv_list, event_interets_plot, all_rr_one_list, all_rr_sublist \u001b[38;5;241m=\u001b[39m  \u001b[43mget_mean_std_event_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsychopy_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_ecg_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_interest_list_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_min_list_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp_hr_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheartrate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m norm_mean_hrv, norm_std_hrv \u001b[38;5;241m=\u001b[39m min_max_norm(all_rr_one_list, all_rr_sublist)\n\u001b[1;32m     42\u001b[0m export_dict\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:sub_id , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_interst\u001b[39m\u001b[38;5;124m'\u001b[39m: event_interets_plot, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_hrv\u001b[39m\u001b[38;5;124m\"\u001b[39m:mean_hrv_list , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd_hrv\u001b[39m\u001b[38;5;124m\"\u001b[39m: std_hrv_list , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_mean_hrv\u001b[39m\u001b[38;5;124m\"\u001b[39m:norm_mean_hrv,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm_std_hrv\u001b[39m\u001b[38;5;124m\"\u001b[39m: norm_std_hrv}\n",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m, in \u001b[0;36mget_mean_std_event_list\u001b[0;34m(psychopy_df, shimmer_df_selected, event_interest_list_new, offset_min_list_new, timestamp_sensor_col_name, data_col_name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#cond_slice_main = (ecg_df_ii[timestamp_sensor_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_sensor_col_name] < timestamp_end_slice)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m ecg_slice \u001b[38;5;241m=\u001b[39m ecg_df_ii\u001b[38;5;241m.\u001b[39mheartrate\n\u001b[0;32m---> 60\u001b[0m peaks, similarity \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_peaks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_slice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m grouped_peaks \u001b[38;5;241m=\u001b[39m group_peaks(peaks)\n\u001b[1;32m     62\u001b[0m grouped_peak_msec \u001b[38;5;241m=\u001b[39mgroup_peaks_from_ind_to_msec(grouped_peaks, \u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m, in \u001b[0;36mdetect_peaks\u001b[0;34m(ecg_signal, threshold, qrs_filter)\u001b[0m\n\u001b[1;32m     11\u001b[0m ecg_signal \u001b[38;5;241m=\u001b[39m (ecg_signal \u001b[38;5;241m-\u001b[39m ecg_signal\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m ecg_signal\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# calculate cross correlation\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecg_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrs_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m similarity \u001b[38;5;241m=\u001b[39m similarity \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(similarity)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# return peaks (values in ms) using threshold\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/sql_dep/lib/python3.9/site-packages/numpy/core/numeric.py:747\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_correlate_dispatcher)\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrelate\u001b[39m(a, v, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    678\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m    Cross-correlation of two 1-dimensional sequences.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate2\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: first array argument cannot be empty"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    \n",
    "    sub_dir_path= os.path.join(data_dir_path, sub_dir)\n",
    "    psychopy_file_path = os.path.join(sub_dir_path, \"Psychopy_data\")\n",
    "    psychopy_file_path = glob.glob(psychopy_file_path+ \"/*.csv\")[0]\n",
    "    #print(psychopy_file_path)\n",
    "    psychopy_df = read_manipulate_psychopy(psychopy_file_path)\n",
    "    \n",
    "    shimmer_files_subdir = os.path.join(sub_dir_path, \"Shimmer_data\")\n",
    "    \n",
    "    shimmer_files_subdir_subdir_name = next(os.walk(shimmer_files_subdir))[1][0]\n",
    "    \n",
    "    shimmer_files_parent_path = os.path.join(shimmer_files_subdir, shimmer_files_subdir_subdir_name)\n",
    "    \n",
    "    shimmer_files_name = glob.glob(shimmer_files_parent_path+ \"/*.csv\")\n",
    "    \n",
    "    for sh_file in shimmer_files_name:\n",
    "        \n",
    "        if '_6B1E_' in sh_file:\n",
    "            hr_shimmer_path = sh_file\n",
    "            \n",
    "    fol_path, file_name=os.path.split(psychopy_file_path)\n",
    "    sub_id=file_name[:-4]\n",
    "    print(sub_id)\n",
    "    \n",
    "    ## heart rate\n",
    "    timestamp_hr_col = \"Shimmer_6B1E_Timestamp_Unix_CAL\"\n",
    "    ecg_col_name = \"Shimmer_6B1E_ECG_LL-LA_24BIT_CAL\"\n",
    "    \n",
    "    hr_df=read_shimmer_sensor(hr_shimmer_path)\n",
    "    hr_df = standardize_timestamps_shimmer(hr_df, timestamp_hr_col)\n",
    "    \n",
    "    selected_ecg_df = hr_df[[timestamp_hr_col, ecg_col_name]]\n",
    "    selected_ecg_df = selected_ecg_df.copy()\n",
    "    selected_ecg_df['heartrate'] = selected_ecg_df[ecg_col_name]\n",
    "    selected_ecg_df=col_from_str_float(selected_ecg_df, \"heartrate\")\n",
    "    \n",
    "    mean_hrv_list,std_hrv_list, event_interets_plot, all_rr_one_list, all_rr_sublist =  get_mean_std_event_list(psychopy_df, selected_ecg_df, event_interest_list_new, offset_min_list_new, timestamp_hr_col, \"heartrate\")\n",
    "    \n",
    "    norm_mean_hrv, norm_std_hrv = min_max_norm(all_rr_one_list, all_rr_sublist)\n",
    "    \n",
    "    export_dict= {\"subject_id\":sub_id , 'event_interst': event_interets_plot, \"mean_hrv\":mean_hrv_list , \"std_hrv\": std_hrv_list , \"norm_mean_hrv\":norm_mean_hrv,  \"norm_std_hrv\": norm_std_hrv}\n",
    "    \n",
    "     \n",
    "    dest_path_csv = os.path.join(comp_dest_path,file_name)\n",
    "    df_export = pd.DataFrame.from_dict(export_dict)\n",
    "    df_export.to_csv(dest_path_csv)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936c02d-db16-4598-b29f-41896b541258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2cc5ee-589a-4f0d-ba37-9dae5e6b07aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facfc6d-19cb-47be-9987-ef9faac651ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b0d5-eabd-4586-8fcb-01f546cf5dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc1f4e-b535-4fe5-b768-9223c4aabfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b759e-1325-40db-9383-b88a40b6fbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3487d6a-478a-474b-951a-ce813be08de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e06d-a0be-4daa-b7ac-4ca61da6341e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c29e72-8dd7-4c8a-8300-867a75e8fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f40f68-bfa1-4d25-9c52-2852bff074e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
