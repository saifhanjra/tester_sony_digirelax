{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f494f18c-6cea-4017-9f1a-a458d8345869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "\n",
    "# misc\n",
    "import warnings\n",
    "\n",
    "import glob\n",
    "\n",
    "##\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d28d5-000e-4d17-82c7-b9f2c6591662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becea94c-695e-4fba-93c7-72b9d757644c",
   "metadata": {},
   "source": [
    "## Psychopy Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9e765042-766d-4762-9699-380986cc5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manipulate_psychopy(psychopy_path):\n",
    "    \n",
    "    psychopy_df = pd.read_csv(psychopy_path)\n",
    "    col_list = [col for col in psychopy_df.columns if col.endswith('_ts')]\n",
    "    col_list.insert(0, \"Reference_time\")\n",
    "    psychopy_df_selected = psychopy_df[col_list]\n",
    "    \n",
    "    return psychopy_df_selected\n",
    "\n",
    "\n",
    "def get_nonNan_list_psychopy(psychopy_df, col_name):\n",
    "    \n",
    "    \n",
    "    selected_vals=[val for val in psychopy_df[col_name].to_list() if not(math.isnan(val))]\n",
    "    \n",
    "    return selected_vals\n",
    "\n",
    "\n",
    "\n",
    "#######---------------------------------------------------\n",
    "###### ------------------Shimmer--------------------------\n",
    "###----------------------------------------------------------\n",
    "\n",
    "\n",
    "def read_shimmer_sensor(sensor_file_path):\n",
    "    \n",
    "    shimmer_df = pd.read_csv(sensor_file_path, sep='\\t', low_memory=False)\n",
    "    shimmer_df = shimmer_df.reset_index()\n",
    "    shimmer_df.columns = shimmer_df.iloc[0]\n",
    "    shimmer_df.drop([0, 1], axis=0, inplace=True)\n",
    "    shimmer_df=shimmer_df.reset_index(drop=True)\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "def standardize_timestamps_shimmer(shimmer_df, timestamps_col_name):\n",
    "    \n",
    "    timesstamps_list = shimmer_df[timestamps_col_name].to_list()\n",
    "    new_timestamps_list = [float(val)/1000 for val in  timesstamps_list]\n",
    "    \n",
    "    shimmer_df[timestamps_col_name] = new_timestamps_list\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "\n",
    "\n",
    "def get_offset_timestamp(timestamp, offset_mins):\n",
    "    \n",
    "    time_zone = 'Europe/Berlin'\n",
    "    tz = pytz.timezone(time_zone)\n",
    "    local_time = dt.datetime.fromtimestamp(timestamp, tz)\n",
    "    time_change = dt.timedelta(minutes=offset_mins)\n",
    "    new_time = local_time + time_change\n",
    "    new_timestamp =  dt.datetime.timestamp(new_time)\n",
    "    return new_timestamp\n",
    "\n",
    "def get_list_timestamp_interest(starting_timestamp, list_offset_mins):\n",
    "    \n",
    "    starting_timestamp_list=[]\n",
    "    \n",
    "    for offset_min in list_offset_mins:\n",
    "        starting_timestamp_list.append(starting_timestamp)\n",
    "        timestamp_offset = get_offset_timestamp(starting_timestamp, offset_min)\n",
    "        starting_timestamp = timestamp_offset  \n",
    "     \n",
    "    \n",
    "    #starting_timestamp_list = sorted(starting_timestamp_list, key = lambda x:float(x))\n",
    "    return starting_timestamp_list\n",
    "        \n",
    "        \n",
    "\n",
    "def slice_df_wrt_timestamps(df, start_timestamp, end_timestamp, timestamps_col):\n",
    "    \n",
    "    sliced_df=df[(df[timestamps_col]>= start_timestamp) & (df[timestamps_col] <= end_timestamp)]\n",
    "    \n",
    "    return sliced_df\n",
    "\n",
    "\n",
    "def from_str_to_float(str_list):\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    return float_array\n",
    "\n",
    "def col_from_str_float (df, col_name):\n",
    "    \n",
    "    str_list = df[col_name].values\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    df[col_name] = float_array\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf5f94-f734-4d84-9998-b457fa874110",
   "metadata": {},
   "source": [
    "## HRV: Time domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f65d0ff5-1954-40d0-a7d4-658f3bc70190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):\n",
    "    '''\n",
    "    Peak detection algorithm using cross corrrelation and threshold \n",
    "    '''\n",
    "    if qrs_filter is None:\n",
    "        # create default qrs filter, which is just a part of the sine function\n",
    "        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)\n",
    "        qrs_filter = np.sin(t)\n",
    "    \n",
    "    # normalize data\n",
    "    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()\n",
    "\n",
    "    # calculate cross correlation\n",
    "    similarity = np.correlate(ecg_signal, qrs_filter, mode=\"same\")\n",
    "    similarity = similarity / np.max(similarity)\n",
    "\n",
    "    # return peaks (values in ms) using threshold\n",
    "    return ecg_signal[similarity > threshold].index, similarity\n",
    "\n",
    "\n",
    "\n",
    "def group_peaks(p, threshold=5):\n",
    "    '''\n",
    "    The peak detection algorithm finds multiple peaks for each QRS complex. \n",
    "    Here we group collections of peaks that are very near (within threshold) and we take the median index \n",
    "    '''\n",
    "    # initialize output\n",
    "    output = np.empty(0)\n",
    "\n",
    "    # label groups of sample that belong to the same peak\n",
    "    peak_groups, num_groups = label(np.diff(p) < threshold)\n",
    "\n",
    "    # iterate through groups and take the mean as peak index\n",
    "    for i in np.unique(peak_groups)[1:]:\n",
    "        peak_group = p[np.where(peak_groups == i)]\n",
    "        output = np.append(output, np.median(peak_group))\n",
    "    return output\n",
    "\n",
    "def group_peaks_from_ind_to_msec(grouped_peaks_ind, sampling_freq):\n",
    "    \n",
    "    \n",
    "    #grouped_peak_ascending = sorted(grouped_peaks_ind, key = lambda x:float(x))\n",
    "    \n",
    "    #grouped_peak_ascending_np=np.array(grouped_peak_ascending)\n",
    "    grouped_peak_sec = grouped_peaks_ind*(1/sampling_freq)\n",
    "    \n",
    "    grouped_peak_msec = grouped_peak_sec*1000\n",
    "    \n",
    "    return grouped_peak_msec\n",
    "    \n",
    "\n",
    "\n",
    "def timedomain(rr):\n",
    "    results = {}\n",
    "\n",
    "    hr = 60000/rr\n",
    "    \n",
    "    results['Mean RR (ms)'] = np.mean(rr)\n",
    "    results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "    #results['Mean HR (Kubios\\' style) (beats/min)'] = 60000/np.mean(rr)\n",
    "    #results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "    #results['STD HR (beats/min)'] = np.std(hr)\n",
    "    #results['Min HR (beats/min)'] = np.min(hr)\n",
    "    #results['Max HR (beats/min)'] = np.max(hr)\n",
    "    results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "    results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 100)*1\n",
    "    results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 100)*1) / len(rr)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def filter_rr(rr, throshold_high=0.5, threshold_low=0.5):\n",
    "    \n",
    "    #outlier_high = np.mean(rr) + throshold_high * np.std(rr)\n",
    "    outlier_high =1400\n",
    "    #print(outlier_high)\n",
    "    \n",
    "    rr_clean_high = [rr_val for rr_val in rr if rr_val <  outlier_high]\n",
    "    \n",
    "    rr_clean_high = np.array(rr_clean_high)\n",
    "    \n",
    "    #outlier_low = np.mean(rr_clean_high) - threshold_low*np.std(rr_clean_high)\n",
    "    outlier_low = 600\n",
    "    #print(outlier_low)\n",
    "    \n",
    "    rr_clean_high_low = [rr_val for rr_val in rr_clean_high if rr_val >  outlier_low]\n",
    "    \n",
    "    rr_clean_high_low= np.array(rr_clean_high_low)\n",
    "    \n",
    "    return rr_clean_high_low\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def min_max_norm(all_rr_one_list, all_rr_sublist):\n",
    "    \n",
    "    mean_norm_list =[]\n",
    "    std_norm_list = []\n",
    "    \n",
    "    all_rr_one_list = np.array(all_rr_one_list)\n",
    "    max_val = np.max(all_rr_one_list)\n",
    "    min_val =np.min(all_rr_one_list)\n",
    "    \n",
    "    for sel_list in all_rr_sublist:\n",
    "        \n",
    "        sel_list_np = np.array(sel_list)\n",
    "        \n",
    "        range_list = max_val-min_val\n",
    "        \n",
    "        sel_lis_np_sub = sel_list_np - min_val\n",
    "        \n",
    "        sel_lis_norm= sel_lis_np_sub/range_list\n",
    "        \n",
    "        mean_norm = np.mean(sel_lis_norm)\n",
    "        mean_norm_list.append(mean_norm)\n",
    "        \n",
    "        std_norm  = np.std(sel_lis_norm)   \n",
    "        std_norm_list.append(std_norm)\n",
    "        #print(mean_norm)\n",
    "        #print(std_norm)\n",
    "                \n",
    "        \n",
    "    return mean_norm_list, std_norm_list\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def get_plot_ranges(start=10, end=20, n=5):\n",
    "    '''\n",
    "    Make an iterator that divides into n or n+1 ranges. \n",
    "    - if end-start is divisible by steps, return n ranges\n",
    "    - if end-start is not divisible by steps, return n+1 ranges, where the last range is smaller and ends at n\n",
    "    \n",
    "    # Example:\n",
    "    >> list(get_plot_ranges())\n",
    "    >> [(0.0, 3.0), (3.0, 6.0), (6.0, 9.0)]\n",
    "\n",
    "    '''\n",
    "    distance = end - start\n",
    "    for i in np.arange(start, end, np.floor(distance/n)):\n",
    "        yield (int(i), int(np.minimum(end, np.floor(distance/n) + i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520976e-dfeb-4c03-a217-d87faceb2b59",
   "metadata": {},
   "source": [
    "## Path and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c7da6bf2-a774-474f-84a5-d0e6e4378f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"/home/muhammad/Desktop/Datasets/data_sony_digiRelax/wp3_tester\"\n",
    "#data_dir_path = \"D:/Datasets/data_sony_digiRelax/study\"\n",
    "sub_dirs=next(os.walk(data_dir_path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61cabf64-698d-4f5b-ad30-22110d082406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VP007_091123']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ad3201b-e38e-42f6-bf9e-aa09188935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_event_list(psychopy_df, shimmer_df_selected, event_interest_list_new, offset_min_list_new, timestamp_sensor_col_name, data_col_name):\n",
    "\n",
    "    mean_cumm_list = []\n",
    "    std_cumm_list  = []\n",
    "    event_interets_plot = []\n",
    "    \n",
    "    all_rr_one_list = []\n",
    "    all_rr_sublist = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ##---outer loop to hnadle muultiple offsets from the selected events \n",
    "    for ind, event_selected in enumerate(event_interest_list_new):\n",
    "\n",
    "        offset_list_selected_event = offset_min_list_new[ind]\n",
    "\n",
    "        #print(event_selected)\n",
    "\n",
    "        current_event_timestamp = get_nonNan_list_psychopy(psychopy_df, event_selected)[0]\n",
    "\n",
    "        offset_min_list_selected = offset_min_list_new[ind]\n",
    "        \n",
    "        acc_min_print = 0\n",
    "\n",
    "        for offset_min in offset_min_list_selected:\n",
    "            \n",
    "            offset_min_print = offset_min + acc_min_print\n",
    "            \n",
    "            acc_min_print = offset_min_print\n",
    "\n",
    "            event_plot = event_selected +\" \"+ str(offset_min_print) + \" min\"\n",
    "            \n",
    "            print(event_plot)\n",
    "            \n",
    "            event_interets_plot.append(event_plot)\n",
    "\n",
    "            timestamp_offset = get_offset_timestamp(current_event_timestamp, offset_min)\n",
    "\n",
    "            start_end_time_list = [current_event_timestamp, timestamp_offset]\n",
    "\n",
    "            timestamp_start_slice = min(start_end_time_list)\n",
    "\n",
    "            timestamp_end_slice = max(start_end_time_list)\n",
    "\n",
    "            sensor_df_ii=slice_df_wrt_timestamps(shimmer_df_selected, timestamp_start_slice, timestamp_end_slice, timestamp_sensor_col_name)\n",
    "            \n",
    "            #print(sensor_df_ii)\n",
    "            \n",
    "            ecg_df_ii=sensor_df_ii.reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            #cond_slice_main = (ecg_df_ii[timestamp_sensor_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_sensor_col_name] < timestamp_end_slice)\n",
    "            \n",
    "            ecg_slice = ecg_df_ii.heartrate\n",
    "            \n",
    "            peaks, similarity = detect_peaks(ecg_slice, threshold=0.3)\n",
    "            grouped_peaks = group_peaks(peaks)\n",
    "            grouped_peak_msec =group_peaks_from_ind_to_msec(grouped_peaks, 256)\n",
    "            rr = np.diff(grouped_peak_msec)\n",
    "            #print(timedomain(rr))\n",
    "            cleaned_rr = filter_rr(rr)\n",
    "            mean_rr = np.mean(cleaned_rr) \n",
    "            std_rr = np.std(cleaned_rr)\n",
    "            \n",
    "            mean_cumm_list.append(mean_rr)\n",
    "            std_cumm_list.append(std_rr)\n",
    "            \n",
    "            all_rr_one_list.extend(cleaned_rr)\n",
    "            all_rr_sublist.append(cleaned_rr)\n",
    "            \n",
    "            \n",
    "            #event_interets_plot\n",
    "            \n",
    "            #print(np.mean(cleaned_rr))\n",
    "            #print(np.std(cleaned_rr))\n",
    "            \n",
    "\n",
    "\n",
    "            current_event_timestamp = timestamp_offset\n",
    "            \n",
    "            \n",
    "            \n",
    "    return mean_cumm_list, std_cumm_list, event_interets_plot, all_rr_one_list, all_rr_sublist\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788fd7b-ba3a-48bc-a2a5-22fdf4baaea0",
   "metadata": {},
   "source": [
    "## Fetching and slicing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3213a9c8-508b-40ae-a348-b038ae64a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_interest_list_new = [\"baseline_instruction_ts\", \"tsst_prep_ts\", \"tsst_pres_ts\", \"relaxation_prep_ts\", \"saliva_probe_4_ts\", \"saliva_probe_4_ts\"]\n",
    "offset_min_list_new  = [[3], [5], [5,5], [5, 5, 5], [-5], [5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "030fbb2c-6e50-4c08-a8e0-cbd1e3605811",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path =\"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp3/results_22sub\"\n",
    "#dest_path = \"D:/Datasets/analysis_digirelax\"\n",
    "designated_folder = \"hrv_analysis\"\n",
    "comp_dest_path = os.path.join(dest_path, designated_folder)\n",
    "\n",
    "isexist = os.path.exists(comp_dest_path)\n",
    "\n",
    "if not isexist:\n",
    "    os.makedirs(comp_dest_path)\n",
    "    print(\"The new directory is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2013beaa-2353-4899-add6-6bc6c651d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP007_091123_DigiRelax_Experiment_2023-11-09_14h19.56.411\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "saliva_probe_4_ts -5 min\n",
      "saliva_probe_4_ts 5 min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    \n",
    "    sub_dir_path= os.path.join(data_dir_path, sub_dir)\n",
    "    psychopy_file_path = os.path.join(sub_dir_path, \"Psychopy_data\")\n",
    "    psychopy_file_path = glob.glob(psychopy_file_path+ \"/*.csv\")[0]\n",
    "    #print(psychopy_file_path)\n",
    "    psychopy_df = read_manipulate_psychopy(psychopy_file_path)\n",
    "    \n",
    "    shimmer_files_subdir = os.path.join(sub_dir_path, \"Shimmer_data\")\n",
    "    \n",
    "    shimmer_files_subdir_subdir_name = next(os.walk(shimmer_files_subdir))[1][0]\n",
    "    \n",
    "    shimmer_files_parent_path = os.path.join(shimmer_files_subdir, shimmer_files_subdir_subdir_name)\n",
    "    \n",
    "    shimmer_files_name = glob.glob(shimmer_files_parent_path+ \"/*.csv\")\n",
    "    \n",
    "    for sh_file in shimmer_files_name:\n",
    "        \n",
    "        if '_6B1E_' in sh_file:\n",
    "            hr_shimmer_path = sh_file\n",
    "            \n",
    "    fol_path, file_name=os.path.split(psychopy_file_path)\n",
    "    sub_id=file_name[:-4]\n",
    "    print(sub_id)\n",
    "    \n",
    "    ## heart rate\n",
    "    timestamp_hr_col = \"Shimmer_6B1E_Timestamp_Unix_CAL\"\n",
    "    ecg_col_name = \"Shimmer_6B1E_ECG_LL-LA_24BIT_CAL\"\n",
    "    \n",
    "    hr_df=read_shimmer_sensor(hr_shimmer_path)\n",
    "    hr_df = standardize_timestamps_shimmer(hr_df, timestamp_hr_col)\n",
    "    \n",
    "    selected_ecg_df = hr_df[[timestamp_hr_col, ecg_col_name]]\n",
    "    selected_ecg_df = selected_ecg_df.copy()\n",
    "    selected_ecg_df['heartrate'] = selected_ecg_df[ecg_col_name]\n",
    "    selected_ecg_df=col_from_str_float(selected_ecg_df, \"heartrate\")\n",
    "    \n",
    "    mean_hrv_list,std_hrv_list, event_interets_plot, all_rr_one_list, all_rr_sublist =  get_mean_std_event_list(psychopy_df, selected_ecg_df, event_interest_list_new, offset_min_list_new, timestamp_hr_col, \"heartrate\")\n",
    "    \n",
    "    norm_mean_hrv, norm_std_hrv = min_max_norm(all_rr_one_list, all_rr_sublist)\n",
    "    \n",
    "    export_dict= {\"subject_id\":sub_id , 'event_interst': event_interets_plot, \"mean_hrv\":mean_hrv_list , \"std_hrv\": std_hrv_list , \"norm_mean_hrv\":norm_mean_hrv,  \"norm_std_hrv\": norm_std_hrv}\n",
    "    \n",
    "     \n",
    "    dest_path_csv = os.path.join(comp_dest_path,file_name)\n",
    "    df_export = pd.DataFrame.from_dict(export_dict)\n",
    "    df_export.to_csv(dest_path_csv)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d936c02d-db16-4598-b29f-41896b541258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject_id': 'VP007_091123_DigiRelax_Experiment_2023-11-09_14h19.56.411',\n",
       " 'event_interst': ['baseline_instruction_ts 3 min',\n",
       "  'tsst_prep_ts 5 min',\n",
       "  'tsst_pres_ts 5 min',\n",
       "  'tsst_pres_ts 10 min',\n",
       "  'relaxation_prep_ts 5 min',\n",
       "  'relaxation_prep_ts 10 min',\n",
       "  'relaxation_prep_ts 15 min',\n",
       "  'saliva_probe_4_ts -5 min',\n",
       "  'saliva_probe_4_ts 5 min'],\n",
       " 'mean_hrv': [1199.170325413223,\n",
       "  1070.75,\n",
       "  971.3664504716982,\n",
       "  946.4236111111111,\n",
       "  1244.9366465336134,\n",
       "  1205.1490045362902,\n",
       "  1201.8019153225807,\n",
       "  1135.8014929149797,\n",
       "  1170.166015625],\n",
       " 'std_hrv': [55.79380123210651,\n",
       "  57.62949497788654,\n",
       "  69.65990740716322,\n",
       "  49.094098903189234,\n",
       "  42.4522730025184,\n",
       "  58.77626581865634,\n",
       "  61.1613732188504,\n",
       "  50.5910438074983,\n",
       "  59.27472750809293],\n",
       " 'norm_mean_hrv': [0.8028266858306384,\n",
       "  0.6122434782608696,\n",
       "  0.4647525293956795,\n",
       "  0.42773590982286636,\n",
       "  0.8707465594933625,\n",
       "  0.8116993922393642,\n",
       "  0.8067321178120617,\n",
       "  0.708783664847738,\n",
       "  0.7597826086956523],\n",
       " 'norm_std_hrv': [0.0828012354517059,\n",
       "  0.0855255113874722,\n",
       "  0.10337934084773207,\n",
       "  0.07285848880705185,\n",
       "  0.06300163413707079,\n",
       "  0.08722738579464362,\n",
       "  0.09076702344362726,\n",
       "  0.07508004182446124,\n",
       "  0.08796713183809735]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8b2cc5ee-589a-4f0d-ba37-9dae5e6b07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp3/results_22sub/hrv_analysis/VP007_091123_DigiRelax_Experiment_2023-11-09_14h19.56.411.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5facfc6d-19cb-47be-9987-ef9faac651ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>event_interst</th>\n",
       "      <th>mean_hrv</th>\n",
       "      <th>std_hrv</th>\n",
       "      <th>norm_mean_hrv</th>\n",
       "      <th>norm_std_hrv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>baseline_instruction_ts 3 min</td>\n",
       "      <td>1199.170325</td>\n",
       "      <td>55.793801</td>\n",
       "      <td>0.802827</td>\n",
       "      <td>0.082801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>tsst_prep_ts 5 min</td>\n",
       "      <td>1070.750000</td>\n",
       "      <td>57.629495</td>\n",
       "      <td>0.612243</td>\n",
       "      <td>0.085526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>tsst_pres_ts 5 min</td>\n",
       "      <td>971.366450</td>\n",
       "      <td>69.659907</td>\n",
       "      <td>0.464753</td>\n",
       "      <td>0.103379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>tsst_pres_ts 10 min</td>\n",
       "      <td>946.423611</td>\n",
       "      <td>49.094099</td>\n",
       "      <td>0.427736</td>\n",
       "      <td>0.072858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>relaxation_prep_ts 5 min</td>\n",
       "      <td>1244.936647</td>\n",
       "      <td>42.452273</td>\n",
       "      <td>0.870747</td>\n",
       "      <td>0.063002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>relaxation_prep_ts 10 min</td>\n",
       "      <td>1205.149005</td>\n",
       "      <td>58.776266</td>\n",
       "      <td>0.811699</td>\n",
       "      <td>0.087227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>relaxation_prep_ts 15 min</td>\n",
       "      <td>1201.801915</td>\n",
       "      <td>61.161373</td>\n",
       "      <td>0.806732</td>\n",
       "      <td>0.090767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>saliva_probe_4_ts -5 min</td>\n",
       "      <td>1135.801493</td>\n",
       "      <td>50.591044</td>\n",
       "      <td>0.708784</td>\n",
       "      <td>0.075080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>VP007_091123_DigiRelax_Experiment_2023-11-09_1...</td>\n",
       "      <td>saliva_probe_4_ts 5 min</td>\n",
       "      <td>1170.166016</td>\n",
       "      <td>59.274728</td>\n",
       "      <td>0.759783</td>\n",
       "      <td>0.087967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         subject_id  \\\n",
       "0           0  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "1           1  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "2           2  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "3           3  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "4           4  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "5           5  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "6           6  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "7           7  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "8           8  VP007_091123_DigiRelax_Experiment_2023-11-09_1...   \n",
       "\n",
       "                   event_interst     mean_hrv    std_hrv  norm_mean_hrv  \\\n",
       "0  baseline_instruction_ts 3 min  1199.170325  55.793801       0.802827   \n",
       "1             tsst_prep_ts 5 min  1070.750000  57.629495       0.612243   \n",
       "2             tsst_pres_ts 5 min   971.366450  69.659907       0.464753   \n",
       "3            tsst_pres_ts 10 min   946.423611  49.094099       0.427736   \n",
       "4       relaxation_prep_ts 5 min  1244.936647  42.452273       0.870747   \n",
       "5      relaxation_prep_ts 10 min  1205.149005  58.776266       0.811699   \n",
       "6      relaxation_prep_ts 15 min  1201.801915  61.161373       0.806732   \n",
       "7       saliva_probe_4_ts -5 min  1135.801493  50.591044       0.708784   \n",
       "8        saliva_probe_4_ts 5 min  1170.166016  59.274728       0.759783   \n",
       "\n",
       "   norm_std_hrv  \n",
       "0      0.082801  \n",
       "1      0.085526  \n",
       "2      0.103379  \n",
       "3      0.072858  \n",
       "4      0.063002  \n",
       "5      0.087227  \n",
       "6      0.090767  \n",
       "7      0.075080  \n",
       "8      0.087967  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f14b0d5-eabd-4586-8fcb-01f546cf5dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc1f4e-b535-4fe5-b768-9223c4aabfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b759e-1325-40db-9383-b88a40b6fbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3487d6a-478a-474b-951a-ce813be08de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e06d-a0be-4daa-b7ac-4ca61da6341e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c29e72-8dd7-4c8a-8300-867a75e8fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f40f68-bfa1-4d25-9c52-2852bff074e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
