{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f494f18c-6cea-4017-9f1a-a458d8345869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "\n",
    "# misc\n",
    "import warnings\n",
    "\n",
    "import glob\n",
    "\n",
    "##\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d28d5-000e-4d17-82c7-b9f2c6591662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "becea94c-695e-4fba-93c7-72b9d757644c",
   "metadata": {},
   "source": [
    "## Psychopy Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e765042-766d-4762-9699-380986cc5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manipulate_psychopy(psychopy_path):\n",
    "    \n",
    "    psychopy_df = pd.read_csv(psychopy_path)\n",
    "    col_list = [col for col in psychopy_df.columns if col.endswith('_ts')]\n",
    "    col_list.insert(0, \"Reference_time\")\n",
    "    psychopy_df_selected = psychopy_df[col_list]\n",
    "    \n",
    "    return psychopy_df_selected\n",
    "\n",
    "\n",
    "def get_nonNan_list_psychopy(psychopy_df, col_name):\n",
    "    \n",
    "    \n",
    "    selected_vals=[val for val in psychopy_df[col_name].to_list() if not(math.isnan(val))]\n",
    "    \n",
    "    return selected_vals\n",
    "\n",
    "\n",
    "\n",
    "#######---------------------------------------------------\n",
    "###### ------------------Shimmer--------------------------\n",
    "###----------------------------------------------------------\n",
    "\n",
    "\n",
    "def read_shimmer_sensor(sensor_file_path):\n",
    "    \n",
    "    shimmer_df = pd.read_csv(sensor_file_path, sep='\\t', low_memory=False)\n",
    "    shimmer_df = shimmer_df.reset_index()\n",
    "    shimmer_df.columns = shimmer_df.iloc[0]\n",
    "    shimmer_df.drop([0, 1], axis=0, inplace=True)\n",
    "    shimmer_df=shimmer_df.reset_index(drop=True)\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "def standardize_timestamps_shimmer(shimmer_df, timestamps_col_name):\n",
    "    \n",
    "    timesstamps_list = shimmer_df[timestamps_col_name].to_list()\n",
    "    new_timestamps_list = [float(val)/1000 for val in  timesstamps_list]\n",
    "    \n",
    "    shimmer_df[timestamps_col_name] = new_timestamps_list\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "\n",
    "\n",
    "def get_offset_timestamp(timestamp, offset_mins):\n",
    "    \n",
    "    time_zone = 'Europe/Berlin'\n",
    "    tz = pytz.timezone(time_zone)\n",
    "    local_time = dt.datetime.fromtimestamp(timestamp, tz)\n",
    "    time_change = dt.timedelta(minutes=offset_mins)\n",
    "    new_time = local_time + time_change\n",
    "    new_timestamp =  dt.datetime.timestamp(new_time)\n",
    "    return new_timestamp\n",
    "\n",
    "def get_list_timestamp_interest(starting_timestamp, list_offset_mins):\n",
    "    \n",
    "    starting_timestamp_list=[]\n",
    "    \n",
    "    for offset_min in list_offset_mins:\n",
    "        starting_timestamp_list.append(starting_timestamp)\n",
    "        timestamp_offset = get_offset_timestamp(starting_timestamp, offset_min)\n",
    "        starting_timestamp = timestamp_offset  \n",
    "     \n",
    "    \n",
    "    #starting_timestamp_list = sorted(starting_timestamp_list, key = lambda x:float(x))\n",
    "    return starting_timestamp_list\n",
    "        \n",
    "        \n",
    "\n",
    "def slice_df_wrt_timestamps(df, start_timestamp, end_timestamp, timestamps_col):\n",
    "    \n",
    "    sliced_df=df[(df[timestamps_col]>= start_timestamp) & (df[timestamps_col] <= end_timestamp)]\n",
    "    \n",
    "    return sliced_df\n",
    "\n",
    "\n",
    "def from_str_to_float(str_list):\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    return float_array\n",
    "\n",
    "def col_from_str_float (df, col_name):\n",
    "    \n",
    "    str_list = df[col_name].values\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    df[col_name] = float_array\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf5f94-f734-4d84-9998-b457fa874110",
   "metadata": {},
   "source": [
    "## HRV: Time domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f65d0ff5-1954-40d0-a7d4-658f3bc70190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):\n",
    "    '''\n",
    "    Peak detection algorithm using cross corrrelation and threshold \n",
    "    '''\n",
    "    if qrs_filter is None:\n",
    "        # create default qrs filter, which is just a part of the sine function\n",
    "        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)\n",
    "        qrs_filter = np.sin(t)\n",
    "    \n",
    "    # normalize data\n",
    "    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()\n",
    "\n",
    "    # calculate cross correlation\n",
    "    similarity = np.correlate(ecg_signal, qrs_filter, mode=\"same\")\n",
    "    similarity = similarity / np.max(similarity)\n",
    "\n",
    "    # return peaks (values in ms) using threshold\n",
    "    return ecg_signal[similarity > threshold].index, similarity\n",
    "\n",
    "\n",
    "\n",
    "def group_peaks(p, threshold=5):\n",
    "    '''\n",
    "    The peak detection algorithm finds multiple peaks for each QRS complex. \n",
    "    Here we group collections of peaks that are very near (within threshold) and we take the median index \n",
    "    '''\n",
    "    # initialize output\n",
    "    output = np.empty(0)\n",
    "\n",
    "    # label groups of sample that belong to the same peak\n",
    "    peak_groups, num_groups = label(np.diff(p) < threshold)\n",
    "\n",
    "    # iterate through groups and take the mean as peak index\n",
    "    for i in np.unique(peak_groups)[1:]:\n",
    "        peak_group = p[np.where(peak_groups == i)]\n",
    "        output = np.append(output, np.median(peak_group))\n",
    "    return output\n",
    "\n",
    "def group_peaks_from_ind_to_msec(grouped_peaks_ind, sampling_freq):\n",
    "    \n",
    "    \n",
    "    #grouped_peak_ascending = sorted(grouped_peaks_ind, key = lambda x:float(x))\n",
    "    \n",
    "    #grouped_peak_ascending_np=np.array(grouped_peak_ascending)\n",
    "    grouped_peak_sec = grouped_peaks_ind*(1/sampling_freq)\n",
    "    \n",
    "    grouped_peak_msec = grouped_peak_sec*1000\n",
    "    \n",
    "    return grouped_peak_msec\n",
    "    \n",
    "\n",
    "\n",
    "def timedomain(rr):\n",
    "    results = {}\n",
    "\n",
    "    hr = 60000/rr\n",
    "    \n",
    "    results['Mean RR (ms)'] = np.mean(rr)\n",
    "    results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "    #results['Mean HR (Kubios\\' style) (beats/min)'] = 60000/np.mean(rr)\n",
    "    #results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "    #results['STD HR (beats/min)'] = np.std(hr)\n",
    "    #results['Min HR (beats/min)'] = np.min(hr)\n",
    "    #results['Max HR (beats/min)'] = np.max(hr)\n",
    "    results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "    results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 100)*1\n",
    "    results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 100)*1) / len(rr)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def filter_rr(rr, throshold_high=0.5, threshold_low=0.5):\n",
    "    \n",
    "    #outlier_high = np.mean(rr) + throshold_high * np.std(rr)\n",
    "    outlier_high =1400\n",
    "    #print(outlier_high)\n",
    "    \n",
    "    rr_clean_high = [rr_val for rr_val in rr if rr_val <  outlier_high]\n",
    "    \n",
    "    rr_clean_high = np.array(rr_clean_high)\n",
    "    \n",
    "    #outlier_low = np.mean(rr_clean_high) - threshold_low*np.std(rr_clean_high)\n",
    "    outlier_low = 600\n",
    "    #print(outlier_low)\n",
    "    \n",
    "    rr_clean_high_low = [rr_val for rr_val in rr_clean_high if rr_val >  outlier_low]\n",
    "    \n",
    "    rr_clean_high_low= np.array(rr_clean_high_low)\n",
    "    \n",
    "    return rr_clean_high_low\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def min_max_norm(all_rr_one_list, all_rr_sublist):\n",
    "    \n",
    "    mean_norm_list =[]\n",
    "    std_norm_list = []\n",
    "    \n",
    "    all_rr_one_list = np.array(all_rr_one_list)\n",
    "    max_val = np.max(all_rr_one_list)\n",
    "    min_val =np.min(all_rr_one_list)\n",
    "    \n",
    "    for sel_list in all_rr_sublist:\n",
    "        \n",
    "        sel_list_np = np.array(sel_list)\n",
    "        \n",
    "        range_list = max_val-min_val\n",
    "        \n",
    "        sel_lis_np_sub = sel_list_np - min_val\n",
    "        \n",
    "        sel_lis_norm= sel_lis_np_sub/range_list\n",
    "        \n",
    "        mean_norm = np.mean(sel_lis_norm)\n",
    "        mean_norm_list.append(mean_norm)\n",
    "        \n",
    "        std_norm  = np.std(sel_lis_norm)   \n",
    "        std_norm_list.append(std_norm)\n",
    "        #print(mean_norm)\n",
    "        #print(std_norm)\n",
    "                \n",
    "        \n",
    "    return mean_norm_list, std_norm_list\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def get_plot_ranges(start=10, end=20, n=5):\n",
    "    '''\n",
    "    Make an iterator that divides into n or n+1 ranges. \n",
    "    - if end-start is divisible by steps, return n ranges\n",
    "    - if end-start is not divisible by steps, return n+1 ranges, where the last range is smaller and ends at n\n",
    "    \n",
    "    # Example:\n",
    "    >> list(get_plot_ranges())\n",
    "    >> [(0.0, 3.0), (3.0, 6.0), (6.0, 9.0)]\n",
    "\n",
    "    '''\n",
    "    distance = end - start\n",
    "    for i in np.arange(start, end, np.floor(distance/n)):\n",
    "        yield (int(i), int(np.minimum(end, np.floor(distance/n) + i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c520976e-dfeb-4c03-a217-d87faceb2b59",
   "metadata": {},
   "source": [
    "## Path and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7da6bf2-a774-474f-84a5-d0e6e4378f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"/home/muhammad/Desktop/Datasets/data_sony_digiRelax/wp3_tester\"\n",
    "#data_dir_path = \"D:/Datasets/data_sony_digiRelax/study\"\n",
    "sub_dirs=next(os.walk(data_dir_path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "61cabf64-698d-4f5b-ad30-22110d082406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VP012_141123']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ad3201b-e38e-42f6-bf9e-aa09188935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_event_list(psychopy_df, shimmer_df_selected, event_interest_list_new, offset_min_list_new, timestamp_sensor_col_name, data_col_name):\n",
    "\n",
    "    mean_cumm_list = []\n",
    "    std_cumm_list  = []\n",
    "    event_interets_plot = []\n",
    "    \n",
    "    all_rr_one_list = []\n",
    "    all_rr_sublist = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ##---outer loop to hnadle muultiple offsets from the selected events \n",
    "    for ind, event_selected in enumerate(event_interest_list_new):\n",
    "\n",
    "        offset_list_selected_event = offset_min_list_new[ind]\n",
    "\n",
    "        #print(event_selected)\n",
    "\n",
    "        current_event_timestamp = get_nonNan_list_psychopy(psychopy_df, event_selected)[0]\n",
    "\n",
    "        offset_min_list_selected = offset_min_list_new[ind]\n",
    "        \n",
    "        acc_min_print = 0\n",
    "\n",
    "        for offset_min in offset_min_list_selected:\n",
    "            \n",
    "            offset_min_print = offset_min + acc_min_print\n",
    "            \n",
    "            acc_min_print = offset_min_print\n",
    "\n",
    "            event_plot = event_selected +\" \"+ str(offset_min_print) + \" min\"\n",
    "            \n",
    "            print(event_plot)\n",
    "            \n",
    "            event_interets_plot.append(event_plot)\n",
    "\n",
    "            timestamp_offset = get_offset_timestamp(current_event_timestamp, offset_min)\n",
    "\n",
    "            start_end_time_list = [current_event_timestamp, timestamp_offset]\n",
    "\n",
    "            timestamp_start_slice = min(start_end_time_list)\n",
    "\n",
    "            timestamp_end_slice = max(start_end_time_list)\n",
    "\n",
    "            sensor_df_ii=slice_df_wrt_timestamps(shimmer_df_selected, timestamp_start_slice, timestamp_end_slice, timestamp_sensor_col_name)\n",
    "            \n",
    "            #print(sensor_df_ii)\n",
    "            \n",
    "            ecg_df_ii=sensor_df_ii.reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            #cond_slice_main = (ecg_df_ii[timestamp_sensor_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_sensor_col_name] < timestamp_end_slice)\n",
    "            \n",
    "            ecg_slice = ecg_df_ii.heartrate\n",
    "            \n",
    "            peaks, similarity = detect_peaks(ecg_slice, threshold=0.3)\n",
    "            grouped_peaks = group_peaks(peaks)\n",
    "            grouped_peak_msec =group_peaks_from_ind_to_msec(grouped_peaks, 256)\n",
    "            rr = np.diff(grouped_peak_msec)\n",
    "            #print(timedomain(rr))\n",
    "            cleaned_rr = filter_rr(rr)\n",
    "            mean_rr = np.mean(cleaned_rr) \n",
    "            std_rr = np.std(cleaned_rr)\n",
    "            \n",
    "            mean_cumm_list.append(mean_rr)\n",
    "            std_cumm_list.append(std_rr)\n",
    "            \n",
    "            all_rr_one_list.extend(cleaned_rr)\n",
    "            all_rr_sublist.append(cleaned_rr)\n",
    "            \n",
    "            \n",
    "            #event_interets_plot\n",
    "            \n",
    "            #print(np.mean(cleaned_rr))\n",
    "            #print(np.std(cleaned_rr))\n",
    "            \n",
    "\n",
    "\n",
    "            current_event_timestamp = timestamp_offset\n",
    "            \n",
    "            \n",
    "            \n",
    "    return mean_cumm_list, std_cumm_list, event_interets_plot, all_rr_one_list, all_rr_sublist\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788fd7b-ba3a-48bc-a2a5-22fdf4baaea0",
   "metadata": {},
   "source": [
    "## Fetching and slicing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3213a9c8-508b-40ae-a348-b038ae64a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_interest_list_new = [\"baseline_instruction_ts\", \"tsst_prep_ts\", \"tsst_pres_ts\", \"relaxation_prep_ts\", \"saliva_probe_4_ts\", \"saliva_probe_4_ts\"]\n",
    "offset_min_list_new  = [[3], [5], [5,5], [5, 5, 5], [-5], [5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "030fbb2c-6e50-4c08-a8e0-cbd1e3605811",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_path =\"/home/muhammad/Desktop/repos_ixp/tester_sony_digirelax/scripts/wp3/results_22sub\"\n",
    "#dest_path = \"D:/Datasets/analysis_digirelax\"\n",
    "designated_folder = \"hrv_analysis\"\n",
    "comp_dest_path = os.path.join(dest_path, designated_folder)\n",
    "\n",
    "isexist = os.path.exists(comp_dest_path)\n",
    "\n",
    "if not isexist:\n",
    "    os.makedirs(comp_dest_path)\n",
    "    print(\"The new directory is created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2013beaa-2353-4899-add6-6bc6c651d0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP012_141123_DigiRelax_Experiment_2023-11-14_09h47.48.508\n",
      "baseline_instruction_ts 3 min\n",
      "tsst_prep_ts 5 min\n",
      "tsst_pres_ts 5 min\n",
      "tsst_pres_ts 10 min\n",
      "relaxation_prep_ts 5 min\n",
      "relaxation_prep_ts 10 min\n",
      "relaxation_prep_ts 15 min\n",
      "saliva_probe_4_ts -5 min\n",
      "saliva_probe_4_ts 5 min\n",
      "0.6158672148621896\n",
      "0.09176892491237636\n",
      "0.37765403594549324\n",
      "0.13105593542782698\n",
      "0.24086116858803824\n",
      "0.11430750730385278\n",
      "0.5158767977820135\n",
      "0.14463052492939155\n",
      "0.6141748890437589\n",
      "0.0870752527384532\n",
      "0.6483249581239532\n",
      "0.0944940769440639\n",
      "0.6660747345751313\n",
      "0.10235098055642905\n",
      "0.592316420813746\n",
      "0.11008711657951784\n",
      "0.529736058935454\n",
      "0.10131586352522709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for sub_dir in sub_dirs:\n",
    "    \n",
    "    sub_dir_path= os.path.join(data_dir_path, sub_dir)\n",
    "    psychopy_file_path = os.path.join(sub_dir_path, \"Psychopy_data\")\n",
    "    psychopy_file_path = glob.glob(psychopy_file_path+ \"/*.csv\")[0]\n",
    "    #print(psychopy_file_path)\n",
    "    psychopy_df = read_manipulate_psychopy(psychopy_file_path)\n",
    "    \n",
    "    shimmer_files_subdir = os.path.join(sub_dir_path, \"Shimmer_data\")\n",
    "    \n",
    "    shimmer_files_subdir_subdir_name = next(os.walk(shimmer_files_subdir))[1][0]\n",
    "    \n",
    "    shimmer_files_parent_path = os.path.join(shimmer_files_subdir, shimmer_files_subdir_subdir_name)\n",
    "    \n",
    "    shimmer_files_name = glob.glob(shimmer_files_parent_path+ \"/*.csv\")\n",
    "    \n",
    "    for sh_file in shimmer_files_name:\n",
    "        \n",
    "        if '_6B1E_' in sh_file:\n",
    "            hr_shimmer_path = sh_file\n",
    "            \n",
    "    fol_path, file_name=os.path.split(psychopy_file_path)\n",
    "    sub_id=file_name[:-4]\n",
    "    print(sub_id)\n",
    "    \n",
    "    ## heart rate\n",
    "    timestamp_hr_col = \"Shimmer_6B1E_Timestamp_Unix_CAL\"\n",
    "    ecg_col_name = \"Shimmer_6B1E_ECG_LL-LA_24BIT_CAL\"\n",
    "    \n",
    "    hr_df=read_shimmer_sensor(hr_shimmer_path)\n",
    "    hr_df = standardize_timestamps_shimmer(hr_df, timestamp_hr_col)\n",
    "    \n",
    "    selected_ecg_df = hr_df[[timestamp_hr_col, ecg_col_name]]\n",
    "    selected_ecg_df = selected_ecg_df.copy()\n",
    "    selected_ecg_df['heartrate'] = selected_ecg_df[ecg_col_name]\n",
    "    selected_ecg_df=col_from_str_float(selected_ecg_df, \"heartrate\")\n",
    "    \n",
    "    mean_hrv_list,std_hrv_list, event_interets_plot, all_rr_one_list, all_rr_sublist =  get_mean_std_event_list(psychopy_df, selected_ecg_df, event_interest_list_new, offset_min_list_new, timestamp_hr_col, \"heartrate\")\n",
    "    \n",
    "    norm_mean_hrv, norm_std_hrv = min_max_norm(all_rr_one_list, all_rr_sublist)\n",
    "    \n",
    "    export_dict= {\"subject_id\":sub_id , 'event_interst': event_interets_plot, \"mean_hrv\":mean_hrv_list , \"std_hrv\": std_hrv_list , \"norm_mean_hrv\":norm_mean_hrv,  \"norm_std_hrv\": norm_std_hrv}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d936c02d-db16-4598-b29f-41896b541258",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rr_one_list = np.array(all_rr_one_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8b2cc5ee-589a-4f0d-ba37-9dae5e6b07aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(all_rr_one_list)\n",
    "min_val =np.min(all_rr_one_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5facfc6d-19cb-47be-9987-ef9faac651ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel_list in all_rr_sublist:\n",
    "    sel_list_np = np.array(sel_list)\n",
    "    \n",
    "    range_list = max_val-min_val\n",
    "    \n",
    "    sel_lis_np_sub = sel_list_np - min_val\n",
    "    \n",
    "    sel_lis_norm= sel_lis_np_sub/range_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f14b0d5-eabd-4586-8fcb-01f546cf5dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66834171, 0.50753769, 0.61809045, 0.67336683, 0.61557789,\n",
       "       0.51758794, 0.4321608 , 0.51256281, 0.56532663, 0.60301508,\n",
       "       0.54020101, 0.43969849, 0.48492462, 0.55527638, 0.63567839,\n",
       "       0.60050251, 0.51005025, 0.51256281, 0.6281407 , 0.62311558,\n",
       "       0.49748744, 0.51758794, 0.58542714, 0.67839196, 0.6959799 ,\n",
       "       0.55527638, 0.57537688, 0.57035176, 0.59045226, 0.54271357,\n",
       "       0.44723618, 0.46984925, 0.51005025, 0.5201005 , 0.31407035,\n",
       "       0.45979899, 0.46482412, 0.54020101, 0.56030151, 0.53517588,\n",
       "       0.48492462, 0.57537688, 0.57286432, 0.56281407, 0.50753769,\n",
       "       0.44723618, 0.49748744, 0.54271357, 0.54271357, 0.43718593,\n",
       "       0.45477387, 0.5201005 , 0.55025126, 0.56532663, 0.51005025,\n",
       "       0.46482412, 0.54020101, 0.52763819, 0.43718593, 0.44472362,\n",
       "       0.42462312, 0.42462312, 0.38442211, 0.58040201, 0.55276382,\n",
       "       0.52261307, 0.38693467, 0.42713568, 0.4798995 , 0.55025126,\n",
       "       0.53768844, 0.57035176, 0.52512563, 0.45979899, 0.40954774,\n",
       "       0.37939698, 0.59045226, 0.57537688, 0.61809045, 0.63567839,\n",
       "       0.59045226, 0.43467337, 0.32160804, 0.30904523, 0.39949749,\n",
       "       0.33919598, 0.3040201 , 0.28643216, 0.4321608 , 0.72864322,\n",
       "       0.53266332, 0.61055276, 0.69849246, 0.70603015, 0.67336683,\n",
       "       0.65577889, 0.54271357, 0.45477387, 0.48492462, 0.69849246,\n",
       "       0.77135678, 0.75125628, 0.74120603])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_lis_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc1f4e-b535-4fe5-b768-9223c4aabfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983b759e-1325-40db-9383-b88a40b6fbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3487d6a-478a-474b-951a-ce813be08de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56e06d-a0be-4daa-b7ac-4ca61da6341e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c29e72-8dd7-4c8a-8300-867a75e8fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f40f68-bfa1-4d25-9c52-2852bff074e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
