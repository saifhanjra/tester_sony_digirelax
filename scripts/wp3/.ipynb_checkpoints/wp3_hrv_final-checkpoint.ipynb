{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded62bf3-92ca-4543-86a9-1708f900d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import seaborn as sns\n",
    "\n",
    "# signal processing\n",
    "from scipy import signal\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import zscore\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "\n",
    "# misc\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import math\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ac7f4f-a0fc-4148-b271-39c483f491a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# style settings\n",
    "sns.set(style='whitegrid', rc={'axes.facecolor': '#EFF2F7'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bf436-bf7d-4778-8bf6-e0b2bc2df53f",
   "metadata": {},
   "source": [
    "## psychopy  and shimmer related "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a4fbdf-125d-42c3-bc46-65b246164d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manipulate_psychopy(psychopy_path):\n",
    "    \n",
    "    psychopy_df = pd.read_csv(psychopy_path)\n",
    "    col_list = [col for col in psychopy_df.columns if col.endswith('_ts')]\n",
    "    col_list.insert(0, \"Reference_time\")\n",
    "    psychopy_df_selected = psychopy_df[col_list]\n",
    "    \n",
    "    return psychopy_df_selected\n",
    "\n",
    "\n",
    "def get_nonNan_list_psychopy(psychopy_df, col_name):\n",
    "    \n",
    "    \n",
    "    selected_vals=[val for val in psychopy_df[col_name].to_list() if not(math.isnan(val))]\n",
    "    \n",
    "    return selected_vals\n",
    "\n",
    "\n",
    "\n",
    "#######---------------------------------------------------\n",
    "###### ------------------Shimmer--------------------------\n",
    "###----------------------------------------------------------\n",
    "\n",
    "\n",
    "def read_shimmer_sensor(sensor_file_path):\n",
    "    \n",
    "    shimmer_df = pd.read_csv(sensor_file_path, sep='\\t', low_memory=False)\n",
    "    shimmer_df = shimmer_df.reset_index()\n",
    "    shimmer_df.columns = shimmer_df.iloc[0]\n",
    "    shimmer_df.drop([0, 1], axis=0, inplace=True)\n",
    "    shimmer_df=shimmer_df.reset_index(drop=True)\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "def standardize_timestamps_shimmer(shimmer_df, timestamps_col_name):\n",
    "    \n",
    "    timesstamps_list = shimmer_df[timestamps_col_name].to_list()\n",
    "    new_timestamps_list = [float(val)/1000 for val in  timesstamps_list]\n",
    "    \n",
    "    shimmer_df[timestamps_col_name] = new_timestamps_list\n",
    "    \n",
    "    return shimmer_df\n",
    "\n",
    "\n",
    "\n",
    "def get_offset_timestamp(timestamp, offset_mins):\n",
    "    \n",
    "    time_zone = 'Europe/Berlin'\n",
    "    tz = pytz.timezone(time_zone)\n",
    "    local_time = dt.datetime.fromtimestamp(timestamp, tz)\n",
    "    time_change = dt.timedelta(minutes=offset_mins)\n",
    "    new_time = local_time + time_change\n",
    "    new_timestamp =  dt.datetime.timestamp(new_time)\n",
    "    return new_timestamp\n",
    "\n",
    "def get_list_timestamp_interest(starting_timestamp, list_offset_mins):\n",
    "    \n",
    "    starting_timestamp_list=[]\n",
    "    \n",
    "    for offset_min in list_offset_mins:\n",
    "        starting_timestamp_list.append(starting_timestamp)\n",
    "        timestamp_offset = get_offset_timestamp(starting_timestamp, offset_min)\n",
    "        starting_timestamp = timestamp_offset  \n",
    "     \n",
    "    \n",
    "    #starting_timestamp_list = sorted(starting_timestamp_list, key = lambda x:float(x))\n",
    "    return starting_timestamp_list\n",
    "        \n",
    "        \n",
    "\n",
    "def slice_df_wrt_timestamps(df, start_timestamp, end_timestamp, timestamps_col):\n",
    "    \n",
    "    sliced_df=df[(df[timestamps_col]>= start_timestamp) & (df[timestamps_col] <= end_timestamp)]\n",
    "    \n",
    "    return sliced_df\n",
    "\n",
    "\n",
    "def from_str_to_float(str_list):\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    return float_array\n",
    "\n",
    "def col_from_str_float (df, col_name):\n",
    "    \n",
    "    str_list = df[col_name].values\n",
    "    \n",
    "    float_array =[float(val) for val in str_list]\n",
    "    \n",
    "    df[col_name] = float_array\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e884f43-5dd0-46ec-a989-6272fe135dd2",
   "metadata": {},
   "source": [
    "## HRV related functions--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1683234a-2d28-42c5-befc-a6de96886bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(ecg_signal, threshold=0.3, qrs_filter=None):\n",
    "    '''\n",
    "    Peak detection algorithm using cross corrrelation and threshold \n",
    "    '''\n",
    "    if qrs_filter is None:\n",
    "        # create default qrs filter, which is just a part of the sine function\n",
    "        t = np.linspace(1.5 * np.pi, 3.5 * np.pi, 15)\n",
    "        qrs_filter = np.sin(t)\n",
    "    \n",
    "    # normalize data\n",
    "    ecg_signal = (ecg_signal - ecg_signal.mean()) / ecg_signal.std()\n",
    "\n",
    "    # calculate cross correlation\n",
    "    similarity = np.correlate(ecg_signal, qrs_filter, mode=\"same\")\n",
    "    similarity = similarity / np.max(similarity)\n",
    "\n",
    "    # return peaks (values in ms) using threshold\n",
    "    return ecg_signal[similarity > threshold].index, similarity\n",
    "\n",
    "\n",
    "\n",
    "def group_peaks(p, threshold=5):\n",
    "    '''\n",
    "    The peak detection algorithm finds multiple peaks for each QRS complex. \n",
    "    Here we group collections of peaks that are very near (within threshold) and we take the median index \n",
    "    '''\n",
    "    # initialize output\n",
    "    output = np.empty(0)\n",
    "\n",
    "    # label groups of sample that belong to the same peak\n",
    "    peak_groups, num_groups = label(np.diff(p) < threshold)\n",
    "\n",
    "    # iterate through groups and take the mean as peak index\n",
    "    for i in np.unique(peak_groups)[1:]:\n",
    "        peak_group = p[np.where(peak_groups == i)]\n",
    "        output = np.append(output, np.median(peak_group))\n",
    "    return output\n",
    "\n",
    "def group_peaks_from_ind_to_msec(grouped_peaks_ind, sampling_freq):\n",
    "    \n",
    "    \n",
    "    #grouped_peak_ascending = sorted(grouped_peaks_ind, key = lambda x:float(x))\n",
    "    \n",
    "    #grouped_peak_ascending_np=np.array(grouped_peak_ascending)\n",
    "    grouped_peak_sec = grouped_peaks_ind*(1/sampling_freq)\n",
    "    \n",
    "    grouped_peak_msec = grouped_peak_sec*1000\n",
    "    \n",
    "    return grouped_peak_msec\n",
    "    \n",
    "\n",
    "\n",
    "def timedomain(rr):\n",
    "    results = {}\n",
    "\n",
    "    hr = 60000/rr\n",
    "    \n",
    "    results['Mean RR (ms)'] = np.mean(rr)\n",
    "    results['STD RR/SDNN (ms)'] = np.std(rr)\n",
    "    #results['Mean HR (Kubios\\' style) (beats/min)'] = 60000/np.mean(rr)\n",
    "    #results['Mean HR (beats/min)'] = np.mean(hr)\n",
    "    #results['STD HR (beats/min)'] = np.std(hr)\n",
    "    #results['Min HR (beats/min)'] = np.min(hr)\n",
    "    #results['Max HR (beats/min)'] = np.max(hr)\n",
    "    results['RMSSD (ms)'] = np.sqrt(np.mean(np.square(np.diff(rr))))\n",
    "    results['NNxx'] = np.sum(np.abs(np.diff(rr)) > 100)*1\n",
    "    results['pNNxx (%)'] = 100 * np.sum((np.abs(np.diff(rr)) > 100)*1) / len(rr)\n",
    "    return results\n",
    "\n",
    "\n",
    "def remove_outliers(grouped_peaks, std_thre):\n",
    "    \n",
    "    rr_diff = np.diff(grouped_peaks)\n",
    "    \n",
    "    mean_diff=np.mean(rr_diff)\n",
    "    \n",
    "    std_diff = np.std(rr_diff)\n",
    "    \n",
    "    ind_interest = [ind_i for ind_i, x  in enumerate(rr_diff) if (x > mean_diff - std_thre* std_diff) and (x < mean_diff + std_thre*std_diff)]\n",
    "    \n",
    "    return rr_diff, ind_interest\n",
    "\n",
    "def filtered_rr(rr_diff, ind_interest):\n",
    "    \n",
    "    rr_diff_new_list = []\n",
    "    \n",
    "    for sel_ind in ind_interest:\n",
    "        \n",
    "        rr_diff_selected = rr_diff[sel_ind]\n",
    "        \n",
    "        rr_diff_new_list.append(rr_diff_selected)\n",
    "        \n",
    "    return rr_diff_new_list\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def get_plot_ranges(start=10, end=20, n=5):\n",
    "    '''\n",
    "    Make an iterator that divides into n or n+1 ranges. \n",
    "    - if end-start is divisible by steps, return n ranges\n",
    "    - if end-start is not divisible by steps, return n+1 ranges, where the last range is smaller and ends at n\n",
    "    \n",
    "    # Example:\n",
    "    >> list(get_plot_ranges())\n",
    "    >> [(0.0, 3.0), (3.0, 6.0), (6.0, 9.0)]\n",
    "\n",
    "    '''\n",
    "    distance = end - start\n",
    "    for i in np.arange(start, end, np.floor(distance/n)):\n",
    "        yield (int(i), int(np.minimum(end, np.floor(distance/n) + i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47db0c0-2d4b-428e-88aa-2dbadc11afc5",
   "metadata": {},
   "source": [
    "## paths  and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5dd15e3d-05fd-4ab5-9f3a-c8c246a5d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "psychopy_file_path = \"/home/muhammad/Desktop/Datasets/data_sony_digiRelax/wp3/VP007_091123/Psychopy_data/VP007_091123_DigiRelax_Experiment_2023-11-09_14h19.56.411.csv\"\n",
    "col_interest_psychopy = \"tsst_pres_ts\"\n",
    "list_offset_mins = [5]\n",
    "selec_ind = 0\n",
    "sampling_frequency = 256\n",
    "ecg_file_path = \"/home/muhammad/Desktop/Datasets/data_sony_digiRelax/wp3/VP007_091123/Shimmer_data/2023-11-09_12.38.31_VP007_091123_SD_Session1/VP007_091123_Session1_Shimmer_6B1E_Calibrated_SD.csv\"\n",
    "ecg_col_name = \"Shimmer_6B1E_ECG_LL-LA_24BIT_CAL\"\n",
    "timestamp_shimmer_col_name = \"Shimmer_6B1E_Timestamp_Unix_CAL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d8ad805-dc7c-46fd-9abd-1b36736b5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####-------------------extracting psychopy inofomration--------------------------\n",
    "psychopy_df = read_manipulate_psychopy(psychopy_file_path)\n",
    "timestamp_ineterest = get_nonNan_list_psychopy(psychopy_df, col_interest_psychopy)[0]\n",
    "\n",
    "######------------- extracting heart rate information----------------------------------\n",
    "ecg_df = read_shimmer_sensor(ecg_file_path)\n",
    "selected_ecg_df = ecg_df[[timestamp_shimmer_col_name, ecg_col_name]]\n",
    "selected_ecg_df = selected_ecg_df.copy()\n",
    "selected_ecg_df = standardize_timestamps_shimmer(selected_ecg_df, timestamp_shimmer_col_name)\n",
    "selected_ecg_df['heartrate'] = selected_ecg_df[ecg_col_name]\n",
    "selected_ecg_df=col_from_str_float (selected_ecg_df, \"heartrate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26e3e0fe-10e9-4f09-8d1c-47cfb6414840",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_interest_list = get_list_timestamp_interest(timestamp_ineterest, list_offset_mins)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a221395-60b7-45cd-beb4-e972404b95c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03026d50-d1eb-4878-a72f-cbfba84f6dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce764095-453c-46ca-b3de-644918beba21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51bef3-17a2-4b48-b145-b657c7995196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "720d252b-ff4c-43cf-b32e-ac986f3b4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_ineterest = timestamps_interest_list[selec_ind]\n",
    "offset_min = list_offset_mins[selec_ind]\n",
    "timestamp_offset = get_offset_timestamp(timestamp_ineterest, offset_min)\n",
    "start_end_time_list = [timestamp_ineterest, timestamp_offset]\n",
    "timestamp_start_slice = min(start_end_time_list)\n",
    "timestamp_end_slice = max(start_end_time_list)\n",
    "\n",
    "ecg_df_ii=slice_df_wrt_timestamps(selected_ecg_df, timestamp_start_slice, timestamp_end_slice, timestamp_shimmer_col_name)\n",
    "ecg_df_ii=ecg_df_ii.reset_index(drop=True)\n",
    "\n",
    "\n",
    "start = 0\n",
    "stop =sampling_frequency*60*offset_min\n",
    "duration = (stop-start) / sampling_frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "20570770-64e9-4b27-9d9a-ac6cf47fc7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9009f73a-f1a4-43d0-a132-b35789aead97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_slice = (ecg_df_ii[timestamp_shimmer_col_name] >= timestamp_start_slice) & (ecg_df_ii[timestamp_shimmer_col_name] < timestamp_end_slice)\n",
    "ecg_slice = ecg_df_ii.heartrate[cond_slice] \n",
    "# detect peaks\n",
    "peaks, similarity = detect_peaks(ecg_slice, threshold=0.3)\n",
    "grouped_peaks = group_peaks(peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "092ad558-2b9c-425a-a45b-3c006dde7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_thre=0.5\n",
    "rr_vals, ind_interest = remove_outliers(grouped_peaks, std_thre)\n",
    "\n",
    "selected_rr_vals = filtered_rr(rr_vals, ind_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd92b8f7-df0a-4098-8d53-e32861d5bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.2719298245614"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(selected_rr_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec77d170-ecb3-4640-bada-2202bffacbeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b4704-559d-4a29-b85c-8b60b9a71af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a4c78-f75d-416f-b731-dfcba9959b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c9332-36bb-4725-be48-940e6026b8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3649f3e-a907-4fa5-a935-ec60e64b9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61adde4-828a-48eb-885a-ef3861b51fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1712ea-7f08-4516-82db-38c51d4f6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80e5e9-eb79-48ac-b874-9b504f586252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdad40f-de20-43d9-abca-ef41ed775571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca6403d-f7dd-411f-815e-7e21116a22c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec951f9-2731-476d-a1c9-076f47969cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
